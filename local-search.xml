<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>PxMAF-X学习</title>
    <link href="/2025/07/08/PxMAF-X%E5%AD%A6%E4%B9%A0/"/>
    <url>/2025/07/08/PxMAF-X%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="pxmaf-x学习">PxMAF-X学习</h1><p>本篇较为复杂，笔者也是边学边写，所以可能不能形成总体—&gt;细节拆分的布局，只能先暂时是分点—&gt;总结的学习步骤</p><h2 id="瓶颈块">瓶颈块</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Bottleneck</span>(nn.Module):<br>    expansion = <span class="hljs-number">4</span> <span class="hljs-comment"># 输出通道数是中间通道数的4倍</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, inplanes, planes, stride=<span class="hljs-number">1</span>, downsample=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-comment"># inplanes:输入通道数</span><br>        <span class="hljs-comment"># planes:压缩过后的中间层通道数</span><br>        <span class="hljs-comment"># stride:步长，控制特征图尺寸</span><br>        <span class="hljs-comment"># downsample:下采样（当输入和输出尺寸不匹配时使用）</span><br>        <span class="hljs-built_in">super</span>(Bottleneck, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-comment"># 1x1卷积:压缩</span><br>        <span class="hljs-variable language_">self</span>.conv1 = nn.Conv2d(inplanes, planes, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)<br>        <span class="hljs-variable language_">self</span>.bn1 = nn.BatchNorm2d(planes)<br>        <span class="hljs-comment"># 3x3卷积:处理</span><br>        <span class="hljs-variable language_">self</span>.conv2 = nn.Conv2d(planes, planes, kernel_size=<span class="hljs-number">3</span>, stride=stride,<br>                               padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)<br>        <span class="hljs-variable language_">self</span>.bn2 = nn.BatchNorm2d(planes)<br>        <span class="hljs-comment"># 1x1卷积:解压</span><br>        <span class="hljs-variable language_">self</span>.conv3 = nn.Conv2d(planes, planes * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)<br>        <span class="hljs-variable language_">self</span>.bn3 = nn.BatchNorm2d(planes * <span class="hljs-number">4</span>)<br>        <span class="hljs-variable language_">self</span>.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<span class="hljs-comment"># 激活函数</span><br>        <span class="hljs-variable language_">self</span>.downsample = downsample<br>        <span class="hljs-variable language_">self</span>.stride = stride<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>   residual = x  <span class="hljs-comment"># 保存原始输入（捷径）</span><br><br>    <span class="hljs-comment"># 主路径：三层卷积</span><br>    out = <span class="hljs-variable language_">self</span>.conv1(x)<br>    out = <span class="hljs-variable language_">self</span>.bn1(out)<br>    out = <span class="hljs-variable language_">self</span>.relu(out)<br><br>    out = <span class="hljs-variable language_">self</span>.conv2(out)<br>    out = <span class="hljs-variable language_">self</span>.bn2(out)<br>    out = <span class="hljs-variable language_">self</span>.relu(out)<br><br>    out = <span class="hljs-variable language_">self</span>.conv3(out)<br>    out = <span class="hljs-variable language_">self</span>.bn3(out)<br><br>    <span class="hljs-comment"># 如果需要下采样（输入和输出尺寸不匹配），对原始输入也做下采样</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.downsample <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        residual = <span class="hljs-variable language_">self</span>.downsample(x)<br><br>    out += residual  <span class="hljs-comment"># 主路径输出+原始输入（残差连接）</span><br>    out = <span class="hljs-variable language_">self</span>.relu(out)  <span class="hljs-comment"># 最后再通过激活函数</span><br><br>    <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure><p>这段定义了一个类定义的是ResNet中的瓶颈块，ResNet是残差网络，其主要的作用就是在神经网络传递的过程中解决退化问题，神经网络在不断的传递过程中，信息会存在偏差或缺失，这就导致深层次的神经网络可能会比浅层次的网络效果更差，而ResNet就是为了解决这个问题，主要得解决办法就是“抄近路”，每几层就加上一条“捷径”，让信息跳过中间层直接传递，这样就保证了信息不会丢失，而其中的基本单元就是<strong>残差块</strong>，残差快包括两个部分，分别是主路径和捷径，而我们这边定义的<strong>瓶颈块</strong>就是一种特殊的残差块，它是通过三个卷积层的组合，来完成一个压缩- 处理 - 解压的过程。我在代码上加了一些注释，应该可以帮助理解。</p><p>举一个实例，就是这个样子</p><p>假设输入是256通道的特征图，中间层通道数设为64：</p><ol type="1"><li><p>压缩阶段（1x1 卷积）：</p><p>输入：256 通道 → <code>conv1</code> → 64 通道</p><p>减少了 3/4 的通道数，降低计算量</p></li><li><p>处理阶段（3x3 卷积）：</p><p>64 通道 → <code>conv2</code> → 64 通道</p><p>保持通道数不变，专注提取特征</p></li><li><p>解压阶段（1x1 卷积）：</p><p>64 通道 → <code>conv3</code> → 256 通道（恢复原始通道数）</p></li><li><p>残差连接：</p><p>将原始输入（256 通道）直接加到处理后的输出上</p><p>公式：<code>最终输出 = 卷积处理结果 + 原始输入</code></p></li></ol><h3 id="conv2d函数的意思">Conv2d函数的意思</h3><p>代码中有这样一行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">nn.Conv2d(inplanes, planes, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p><code>Conv2d</code>是什么呢？这行代码表示的是一个1x1卷积层，它在这里负责两件事，第一个是把高通道数压成低通道数，第二个是再把低通道数恢复到高通道数，我们用最通俗的话来说，就是如果你是一个乐队演奏家，要调整现在的乐器的音量：你原先有10个乐器（通道）同时演奏，现在你对它们进行1x1卷积，给每个乐器提供一个“音量调整系数”，在调整后，就可以只用保持5个乐器的声音（通道数减少），或者达到20个乐器的效果（通道数增加）</p><h3 id="batchnorm2d函数的意思">BatchNorm2d函数的意思</h3><p>还有这样的一行代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-variable language_">self</span>.bn1 = nn.BatchNorm2d(planes)<br></code></pre></td></tr></table></figure><p><code>BatchNorm2d</code>又是什么呢？这里是使用了PyTorch创建了一个<strong>二维批量归一化层（BatchNormalization）</strong>，简称<strong>BN层</strong>，这个看起来抽象难以理解，实际上它做了两件事，<strong>归一化</strong>和<strong>缩放与平移</strong>，首先，对当前批次（Batch）中的所有样本，计算每个通道的均值和方差。然后，用公式：<spanclass="math inline">$(x - 均值) / \sqrt(方差 + \epsilon)$</span>，其中$$是一个很小的数（如1e-5），防止除零错误（基本操作）。最后，使用两个可学习的参数：</p><p><spanclass="math inline"><em>γ</em></span>（缩放因子）：控制数据的缩放程度</p><p><spanclass="math inline"><em>β</em></span>（平移因子）：控制数据的平移程度</p><p>公式：<spanclass="math inline"><em>γ</em> * <em>归</em><em>一</em><em>化</em><em>后</em><em>的</em><em>数</em><em>据</em> + <em>β</em></span></p><p>这里需要指出的是，在上面的归一化公式计算过后，数据的结果会变成均值0，方差1（有兴趣的可以推导一下）</p><p>这里举一个非常通俗易懂的例子来解释BN层的作用：</p><p>如果你是大学里面的一个老师，你教的班很多同学都要挂科了，为了你们班上的及格率，你使出了你的“捞人大法”，先用<spanclass="math inline">$(x - 均值) / \sqrt(方差 +\epsilon)$</span>将分数变为平均分0，标准差为1的一串数，然后你开始设置你的<spanclass="math inline"><em>γ</em></span>和<spanclass="math inline"><em>β</em></span>值，如果你想平均分为70，那么你就将<spanclass="math inline"><em>β</em></span>调整为70，如果你分数差距能够大一些，那么就将<spanclass="math inline"><em>γ</em></span>设置得更大一些，比如1.5</p><h3 id="relu函数的意思">RELU函数的意思</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-variable language_">self</span>.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p><code>RELU</code>是什么意思？简单来说，<strong>ReLU 把所有负数变成0，正数保持不变</strong>，就是一个非常简单的函数，但是它具有什么样的意义呢？两个意义：一个是引入非线性，激活函数显而易见是非线性函数，如果没有激活函数，无论神经网络有多少层，最终都等价于一个线性函数（因为线性变换的组合还是线性的）第二个，在一定程度上能够解决梯度的消失问题（这块我也没有太搞懂，查的资料上是这么讲的），这里的梯度其实就是高数里面梯度概念的衍生，梯度是用来指示神经网络应该朝哪个方向去调整的，并且调整多少。</p><h2 id="骨干网络">骨干网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResNetBackbone</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, block, layers, in_channels=<span class="hljs-number">3</span></span>):<br>        <span class="hljs-variable language_">self</span>.inplanes = <span class="hljs-number">64</span><br>        <span class="hljs-built_in">super</span>(ResNetBackbone, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-comment"># 通过7x7卷积+BN+ReLU+最大池化，快速缩小特征图尺寸（降维）</span><br>        <span class="hljs-variable language_">self</span>.conv1 = nn.Conv2d(in_channels, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">7</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>, bias=<span class="hljs-literal">False</span>)<br>        <span class="hljs-variable language_">self</span>.bn1 = nn.BatchNorm2d(<span class="hljs-number">64</span>)<br>        <span class="hljs-variable language_">self</span>.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        <span class="hljs-variable language_">self</span>.maxpool = nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># layer1：通道数 64，特征图尺寸不变</span><br>        <span class="hljs-comment"># layer2：通道数 128，特征图尺寸减半（stride=2）</span><br>    <span class="hljs-comment"># layer3：通道数 256，特征图尺寸减半</span><br>        <span class="hljs-comment"># layer4：通道数 512，特征图尺寸减半</span><br>        <span class="hljs-variable language_">self</span>.layer1 = <span class="hljs-variable language_">self</span>._make_layer(block, <span class="hljs-number">64</span>, layers[<span class="hljs-number">0</span>])<br>        <span class="hljs-variable language_">self</span>.layer2 = <span class="hljs-variable language_">self</span>._make_layer(block, <span class="hljs-number">128</span>, layers[<span class="hljs-number">1</span>], stride=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.layer3 = <span class="hljs-variable language_">self</span>._make_layer(block, <span class="hljs-number">256</span>, layers[<span class="hljs-number">2</span>], stride=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.layer4 = <span class="hljs-variable language_">self</span>._make_layer(block, <span class="hljs-number">512</span>, layers[<span class="hljs-number">3</span>], stride=<span class="hljs-number">2</span>)<br><span class="hljs-comment"># 随着层数加深，通道数增加，特征图尺寸减小，抓住更多特征，抽离出更多关键信息</span><br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.modules():<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Conv2d):<br>                nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>            <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, nn.BatchNorm2d):<br>                nn.init.constant_(m.weight, <span class="hljs-number">1</span>)<br>                nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_layer</span>(<span class="hljs-params">self, block, planes, blocks, stride=<span class="hljs-number">1</span></span>):<br>        downsample = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> stride != <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> <span class="hljs-variable language_">self</span>.inplanes != planes * block.expansion:<br>            downsample = nn.Sequential(<br>                nn.Conv2d(<span class="hljs-variable language_">self</span>.inplanes, planes * block.expansion,<br>                          kernel_size=<span class="hljs-number">1</span>, stride=stride, bias=<span class="hljs-literal">False</span>),<br>                nn.BatchNorm2d(planes * block.expansion),<br>            )<br><br>        layers = []<br>        layers.append(block(<span class="hljs-variable language_">self</span>.inplanes, planes, stride, downsample))<br>        <span class="hljs-variable language_">self</span>.inplanes = planes * block.expansion<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, blocks):<br>            layers.append(block(<span class="hljs-variable language_">self</span>.inplanes, planes))<br><br>        <span class="hljs-keyword">return</span> nn.Sequential(*layers)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 通过第一个卷积层和池化层，得到初始特征</span><br>        x = <span class="hljs-variable language_">self</span>.conv1(x)<br>        x = <span class="hljs-variable language_">self</span>.bn1(x)<br>        x = <span class="hljs-variable language_">self</span>.relu(x)<br>        x = <span class="hljs-variable language_">self</span>.maxpool(x)<br>    <span class="hljs-comment"># 逐层提取特征，每层输出的特征图尺寸逐渐减小，通道数逐渐增加</span><br>        x1 = <span class="hljs-variable language_">self</span>.layer1(x)<br>        x2 = <span class="hljs-variable language_">self</span>.layer2(x1)<br>        x3 = <span class="hljs-variable language_">self</span>.layer3(x2)<br>        x4 = <span class="hljs-variable language_">self</span>.layer4(x3)<br>   <span class="hljs-comment"># 返回四层的特征图，用于后续任务</span><br>        <span class="hljs-keyword">return</span> [x1, x2, x3, x4]<br></code></pre></td></tr></table></figure><p>这一块是ResNet的核心部分，前面和后面基本上跟上一段还是很像的，我加了一些注释，应该没有问题，难点应该是在19-41行之间，但是在这之前，我们先补一个小点，就是<code>maxpool</code>函数的意思</p><h3 id="maxpool函数的意思">maxpool函数的意思</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-variable language_">self</span>.maxpool = nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>这个函数也是PyTorch里面的，意思为最大池化层，最大池化就像一个“筛选器”，它在输入数据上滑动一个小窗口，每次只保留窗口内的<strong>最大值</strong>，其他值全部丢弃。我们的<code>kernel_size</code>就是池化窗口的大小（单位也是像素），<code>stride</code>是每次走的步长（单位是像素），<code>padding</code>在输入数据周围填充多少圈0（这里是1圈）</p><p>我们在进行池化后，提取出了图像中最为主要的特征，并且减小了数据尺寸</p><h3 id="kaiming-初始化方法">Kaiming 初始化方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br></code></pre></td></tr></table></figure><p>Kaiming初始化是专门为ReLU激活函数设计的初始化方法，它的目标是：让神经网络各层的激活值和梯度的方差在传播过程中保持稳定，避免出现梯度消失或爆炸。</p><p>这里讲的有些抽象了，我们先来解决一下里面的参数的意义：</p><p><code>m.weight</code>：需要初始化的卷积层权重张量。</p><p><code>mode='fan_out'</code>：</p><ul><li>控制权重初始化的缩放因子。</li><li><code>'fan_out'</code>保持输出方差的稳定性（更适合卷积层）。</li></ul><p><code>nonlinearity='relu'</code>：</p><ul><li>指定激活函数类型为 ReLU。</li><li>Kaiming初始化会根据不同的激活函数调整缩放因子（ReLU舍弃掉了负的一半区间，ReLU需要额外除以 2）。</li></ul><p>初始化的结果是，让权重服从正态分布，标准差为<spanclass="math inline">$\sqrt(\frac{2}{fanout})$</span>，<code>fan_out</code>表示输出通道数，控制方差以保持梯度稳定。</p><p>如果觉得这个表述还是太抽象的话，举个最简单的例子：如果组织一场接力赛，如果我们每个选手的初始跑步速度都是随机的，那么可能会出现几个问题，前面的选手跑得太快，后面的选手接不住棒（梯度爆炸），前面的选手跑得太慢，接力棒到后面几乎停了（梯度消失），而我们的Kaiming初始化就是根据赛道长度和选手数量，精确计算每个选手的初始速度，确保接力棒能稳定、快速地传递到终点。</p><p>这个初始化方法基本上就是对照着ReLU激活来的，也是特别适合ResNet这种大量使用ReLU的网络。</p><p>那么我们终于可以开始解释了</p><h3 id="参数初始化操作">参数初始化操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.modules():<span class="hljs-comment"># 遍历模型中的每一个层（包括卷积层、BN层、ReLU等）</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Conv2d):<br>nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br><span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, nn.BatchNorm2d):<br>nn.init.constant_(m.weight, <span class="hljs-number">1</span>)<br>nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>前置的东西讲完，这个东西就很好解释了，这段代码就是神经网络里面的参数初始化操作，它会遍历模型里面的每一个层，并且根据层的类型设置不同的初始值，如果是卷积层，那么就使用Kaiming初始化，如果是BN层，就使用BatchNorm层初始化（前文都有介绍）。其实，这些初始化，都是为了保证梯度在神经网络中传递的稳定性</p><h3 id="make_layer函数">_make_layer函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_layer</span>(<span class="hljs-params">self, block, planes, blocks, stride=<span class="hljs-number">1</span></span>):<br>    <span class="hljs-comment"># block: 残差块类型（如Bottleneck）</span><br>    <span class="hljs-comment"># planes: 基础通道数（如64、128等）</span><br>    <span class="hljs-comment"># blocks: 该层包含的残差块数量</span><br>    <span class="hljs-comment"># stride: 步长，控制特征图尺寸是否减半（默认为1）</span><br>    downsample = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">if</span> stride != <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> <span class="hljs-variable language_">self</span>.inplanes != planes * block.expansion:<br>        downsample = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-variable language_">self</span>.inplanes, planes * block.expansion,<br>                      kernel_size=<span class="hljs-number">1</span>, stride=stride, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(planes * block.expansion),<br>        )<br><br>    layers = []<br>    layers.append(block(<span class="hljs-variable language_">self</span>.inplanes, planes, stride, downsample))<br>    <span class="hljs-variable language_">self</span>.inplanes = planes * block.expansion<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, blocks):<br>        layers.append(block(<span class="hljs-variable language_">self</span>.inplanes, planes))<br><br>    <span class="hljs-keyword">return</span> nn.Sequential(*layers)<br></code></pre></td></tr></table></figure><p>我把参数的意义写在备注上，接下来就是解释了，这一段是定义ResNet中的“残差层”的核心逻辑，就是通过堆叠多个残差块来组成网络的一层，这是一个大层，而这个大层的特点就是第一层可能包括下采样（downsample）操作，用于调整特征图的尺寸和通道数，后续层保持相同的通道数和特征图尺寸，这里我再解释一下什么是下采样，下采样可以简单的理解为“缩小图片”的操作，目的是让图片变小同时保留重要信息，至于下采样的方式，就是可以用之前的“池化层”，每隔两个像素来取一个最大值，图片直接编程之前的一半，或者使用1x1的卷积层，通过调整步长，比如stride=2，让输出的图片尺寸缩小。</p><p>而我们这边需要判断是否要进行下采样，主要是有两种情况：</p><p><code>stride != 1</code>：需要调整特征图尺寸（通常为 2，即减半）</p><p><code>self.inplanes != planes * block.expansion</code>：输入通道数与输出通道数不匹配</p><p>这边下采样的实现就是用1x1卷积来调整通道参数</p><p>下采样结束之后，其实后续就没什么特殊的了，就是保持相同的通道数和特征图尺寸，输入通道数已经在第一层后更新为<code>planes * block.expansion</code>了</p><p>假设我们要构建 ResNet 的第二层（layer2）：</p><ul><li><code>block</code> = Bottleneck（瓶颈块，expansion=4）</li><li><code>planes</code> = 128</li><li><code>blocks</code> = 4（该层有 4 个瓶颈块）</li><li><code>stride</code> = 2（需要下采样，特征图尺寸减半）</li></ul><p>第一个瓶颈块： - 输入通道数：256（来自 layer1 的输出） -中间通道数：128 - 输出通道数：128×4 = 512 - 包含下采样：1x1卷积（256→512，stride=2） - 特征图尺寸：从 56x56→28x28</p><p>后续三个瓶颈块： - 输入 / 输出通道数：512→512 - 中间通道数：128 -特征图尺寸保持 28x28 不变</p><p>这样子基本上我们的骨干网络就全部讲清楚了，可以不断地往下传。</p><h2 id="特征金字塔网络">特征金字塔网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeaturePyramidNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels_list, out_channels</span>):<br>        <span class="hljs-built_in">super</span>(FeaturePyramidNetwork, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.inner_blocks = nn.ModuleList()<br>        <span class="hljs-variable language_">self</span>.layer_blocks = nn.ModuleList()<br>        <span class="hljs-keyword">for</span> in_channels <span class="hljs-keyword">in</span> in_channels_list:<br>            <span class="hljs-keyword">if</span> in_channels == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-comment"># 1x1 卷积，用于调整不同层级特征的通道数（统一为out_channels）</span><br>            inner_block = nn.Conv2d(in_channels, out_channels, <span class="hljs-number">1</span>)<br>            <span class="hljs-comment"># 3x3 卷积，用于处理融合后的特征</span><br>            layer_block = nn.Conv2d(out_channels, out_channels, <span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>            <span class="hljs-variable language_">self</span>.inner_blocks.append(inner_block)<br>            <span class="hljs-variable language_">self</span>.layer_blocks.append(layer_block)<br><span class="hljs-comment"># 这里还是对每一层进行BN初始化</span><br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.modules():<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Conv2d):<br>                nn.init.kaiming_uniform_(m.weight, a=<span class="hljs-number">1</span>)<br>                nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        last_inner = <span class="hljs-variable language_">self</span>.inner_blocks[-<span class="hljs-number">1</span>](x[-<span class="hljs-number">1</span>])<br>        results = []<br>        results.append(<span class="hljs-variable language_">self</span>.layer_blocks[-<span class="hljs-number">1</span>](last_inner))<br>        <br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x) - <span class="hljs-number">2</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):<br>            inner_lateral = <span class="hljs-variable language_">self</span>.inner_blocks[i](x[i])<br>            feat_shape = inner_lateral.shape[-<span class="hljs-number">2</span>:]<br>            last_inner = F.interpolate(last_inner, size=feat_shape, mode=<span class="hljs-string">&quot;nearest&quot;</span>)<br>            last_inner = last_inner + inner_lateral<br>            results.insert(<span class="hljs-number">0</span>, <span class="hljs-variable language_">self</span>.layer_blocks[i](last_inner))<br><br>        <span class="hljs-keyword">return</span> results<br></code></pre></td></tr></table></figure><p>在上面一个篇章，我们已经处理好了很多个大层，这里面的特征金字塔网络（<strong>FeaturePyramid Network,FPN</strong>），目标是融合不同层级的特征，就是把我们刚刚得到的诸多大层的特征再次融合在一起，使得我们的提取结果既有高度概括的特征，又有细致的细节，就是相当于“显微镜+望远镜”，既能看清细节，又能把握全局</p><p>前半部分的初始化过程我就不多说了，跟前面的内容有很多重合的，后面的<code>forward</code>函数还是有些意思的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>    <span class="hljs-comment"># 处理最深层特征（最高语义，最小尺寸）</span><br>    last_inner = <span class="hljs-variable language_">self</span>.inner_blocks[-<span class="hljs-number">1</span>](x[-<span class="hljs-number">1</span>])<br>    results = [<span class="hljs-variable language_">self</span>.layer_blocks[-<span class="hljs-number">1</span>](last_inner)]<br>    <span class="hljs-comment"># 自顶向下融合过程</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x) - <span class="hljs-number">2</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):<br>        <span class="hljs-comment"># 获取当前层特征并调整通道</span><br>        inner_lateral = <span class="hljs-variable language_">self</span>.inner_blocks[i](x[i])<br>        <span class="hljs-comment"># 上采样高层特征，使其与当前层尺寸匹配</span><br>        last_inner = F.interpolate(last_inner, size=inner_lateral.shape[-<span class="hljs-number">2</span>:], mode=<span class="hljs-string">&quot;nearest&quot;</span>)<br>        <span class="hljs-comment"># 特征融合：将上采样后的高层特征与当前层特征相加</span><br>        last_inner = last_inner + inner_lateral<br>        <span class="hljs-comment"># 处理融合后的特征并保存结果</span><br>        results.insert(<span class="hljs-number">0</span>, <span class="hljs-variable language_">self</span>.layer_blocks[i](last_inner))<br>    <span class="hljs-keyword">return</span> results<br></code></pre></td></tr></table></figure><p>我本来还是想继续写一些东西的，后来觉得代码注释已经把我想写的全部写完了，可能还是会觉得抽象，来举个例子吧：</p><p>假设输入是来自ResNet的四层特征:</p><blockquote><p>C2: 256通道, 尺寸56×56（最浅层）</p><p>C3: 512通道, 尺寸28×28</p><p>C4: 1024通道, 尺寸14×14</p><p>C5: 2048通道, 尺寸7×7（最深层）</p></blockquote><p>用 1x1 卷积将C2→256，C3→256，C4→256，C5→256（假设<code>out_channels=256</code>）</p><p>自顶向下融合：</p><blockquote><p>P5 = 调整后的C5（尺寸7×7）</p><p>P4 = 调整后的C4 + 上采样(P5)（尺寸14×14）</p><p>P3 = 调整后的C3 + 上采样(P4)（尺寸28×28）</p><p>P2 = 调整后的C2 + 上采样(P3)（尺寸56×56）</p></blockquote><p>最终输出：</p><blockquote><p>[P2, P3, P4, P5]（通道数均为256，尺寸从大到小）</p></blockquote><p>大尺寸特征图（如 P2）适合检测小物体（保留了细节）</p><p>小尺寸特征图（如 P5）适合检测大物体（包含了高层语义）</p><p>基本上我们这个FPN也讲清楚了</p><h2 id="多尺度注意力特征">多尺度注意力特征</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MAF_Extractor</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, feat_dim=<span class="hljs-number">2048</span>, maf_dim=<span class="hljs-number">256</span></span>):<br>        <span class="hljs-built_in">super</span>(MAF_Extractor, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.global_avgpool = nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<span class="hljs-comment"># 全局平均池化</span><br>        <span class="hljs-variable language_">self</span>.fc = nn.Linear(feat_dim, maf_dim)<span class="hljs-comment"># 全连接层，降维</span><br>        <span class="hljs-variable language_">self</span>.bn = nn.BatchNorm1d(maf_dim)<span class="hljs-comment"># 批量归一化</span><br>        <span class="hljs-variable language_">self</span>.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<span class="hljs-comment"># 激活函数</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.global_avgpool(x)<span class="hljs-comment"># 压缩特征图为1×1</span><br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<span class="hljs-comment"># 展平为一维向量</span><br>        x = <span class="hljs-variable language_">self</span>.fc(x)<span class="hljs-comment"># 降维：feat_dim → maf_dim</span><br>        x = <span class="hljs-variable language_">self</span>.bn(x)<span class="hljs-comment"># 归一化</span><br>        x = <span class="hljs-variable language_">self</span>.relu(x)<span class="hljs-comment"># 激活函数</span><br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><p>这段定义了一个<strong>MAF_Extractor</strong>（Multi-scale AttentionFeature, MAF）的神经网络模块，如果简单解释MAF_Extractor 就像一个“特征压缩器”，它接收高维的图像特征（例如 ResNet 输出的 2048维特征），通过一系列操作将其转换为低维但更有代表性的特征（例如 256维）。</p><p>里面的函数也非常好理解，很多是之前已经出现过的</p><h3 id="adaptiveavgpool2d函数">AdaptiveAvgPool2d函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-variable language_">self</span>.global_avgpool = nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><p>假设输入是一个<code>C×H×W</code>的特征图（C 是通道数，H 和 W是高度和宽度），全局平均池化会：</p><ol type="1"><li>对每个通道（channel）单独处理</li><li>计算每个通道上所有像素值的平均值</li><li>输出一个<code>C×1×1</code>的向量，每个值对应一个通道的平均值</li></ol><p>这个简单到不需要举例子了</p><p>参数就是矩阵的大小，因为这里输入的是<code>(1,1)</code>，如果两个参数都设成2，那么就会使<code>2x2</code>的矩阵</p><h3 id="linear函数">Linear函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-variable language_">self</span>.fc = nn.Linear(feat_dim, maf_dim)<br></code></pre></td></tr></table></figure><p>全连接层就像一个 “翻译器”，把输入的特征向量（比如 2048 维）“翻译”成另一个维度的向量（比如 256 维）。这个过程可以用一个线性方程表示：</p><blockquote><p><code>y = Wx + b</code></p></blockquote><p><code>x</code> 是输入向量（维度：<code>feat_dim</code>）</p><p><code>W</code>是权重矩阵（维度：<code>maf_dim × feat_dim</code>）</p><p><code>b</code> 是偏置向量（维度：<code>maf_dim</code>）</p><p><code>y</code> 是输出向量（维度：<code>maf_dim</code>）</p><p>全连接层的参数就是<code>W</code>和<code>b</code>，这个数值需要通过训练来得到</p><p><code>feat_dim</code>：输入特征的维度（这里是2048，来自上一层的输出）</p><p><code>maf_dim</code>：输出特征的维度（这里是256，压缩后的特征维度）</p><p>我们需要特别注意的是，这个函数既可以用来降维，也可以用来升维，后面会多次遇到</p><h2 id="姿势回归器">姿势回归器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PoseRegressor</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, feat_dim=<span class="hljs-number">256</span>, output_dim=<span class="hljs-number">24</span>*<span class="hljs-number">3</span>*<span class="hljs-number">3</span></span>):<br>        <span class="hljs-built_in">super</span>(PoseRegressor, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.fc1 = nn.Linear(feat_dim, <span class="hljs-number">1024</span>)<span class="hljs-comment"># 第一个全连接层：升维</span><br>        <span class="hljs-variable language_">self</span>.dropout1 = nn.Dropout(<span class="hljs-number">0.5</span>)<span class="hljs-comment"># 第一个Dropout层</span><br>        <span class="hljs-variable language_">self</span>.fc2 = nn.Linear(<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>)<span class="hljs-comment"># 第二个全连接层</span><br>        <span class="hljs-variable language_">self</span>.dropout2 = nn.Dropout(<span class="hljs-number">0.5</span>)<span class="hljs-comment"># 第二个Dropout层</span><br>        <span class="hljs-variable language_">self</span>.fc3 = nn.Linear(<span class="hljs-number">1024</span>, output_dim)<span class="hljs-comment"># 第三个全连接层：输出结果</span><br>        <span class="hljs-variable language_">self</span>.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<span class="hljs-comment"># ReLU激活函数</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.dropout1(<span class="hljs-variable language_">self</span>.relu(<span class="hljs-variable language_">self</span>.fc1(x)))<span class="hljs-comment"># 第一层：全连接+激活+Dropout</span><br>        x = <span class="hljs-variable language_">self</span>.dropout2(<span class="hljs-variable language_">self</span>.relu(<span class="hljs-variable language_">self</span>.fc2(x)))<span class="hljs-comment"># 第二层：全连接+激活+Dropout</span><br>        x = <span class="hljs-variable language_">self</span>.fc3(x)<span class="hljs-comment"># 第三层：直接输出结果</span><br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><p>这段代码定义了一个<strong>姿态回归器（PoseRegressor）</strong>，它的作用是从输入特征中预测人体的3D 姿态。姿态回归器就像一个“姿势解码器”，它接收一个特征向量（MAF_Extractor 输出的 256维特征），然后预测出人体各个关节的 3D 位置。</p><p>这里面的<code>Dropout</code>让我自己想肯定是想不到的，给的说法是随机丢掉50%的神经元，防止过拟合，这可能是在实践中发现存在错误后而进行的修正吧</p><p>它的特点就是逐步处理特征，从 256 维→1024 维→1024 维→216 维（216 = 24x 3 x3）这个数字代表的就是24个关节点，每个关节点用3*3的旋转矩阵来表示，就是SMPL的核心参量了</p><p>为什么要升维？从 256 维升到 1024 维，让模型有更多 “空间”学习复杂的姿势特征但是可能也是意味着维数越多，拟合出来的就越精确吧，反正<code>Linear</code>函数里面的<code>W</code>和<code>b</code>都是训练出来的，只要给合适的数据就行。</p><h2 id="形状回归器">形状回归器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ShapeRegressor</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, feat_dim=<span class="hljs-number">256</span>, output_dim=<span class="hljs-number">10</span></span>):<br>        <span class="hljs-built_in">super</span>(ShapeRegressor, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.fc1 = nn.Linear(feat_dim, <span class="hljs-number">1024</span>)<br>        <span class="hljs-variable language_">self</span>.dropout1 = nn.Dropout(<span class="hljs-number">0.5</span>)<br>        <span class="hljs-variable language_">self</span>.fc2 = nn.Linear(<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>)<br>        <span class="hljs-variable language_">self</span>.dropout2 = nn.Dropout(<span class="hljs-number">0.5</span>)<br>        <span class="hljs-variable language_">self</span>.fc3 = nn.Linear(<span class="hljs-number">1024</span>, output_dim)<br>        <span class="hljs-variable language_">self</span>.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.dropout1(<span class="hljs-variable language_">self</span>.relu(<span class="hljs-variable language_">self</span>.fc1(x)))<br>        x = <span class="hljs-variable language_">self</span>.dropout2(<span class="hljs-variable language_">self</span>.relu(<span class="hljs-variable language_">self</span>.fc2(x)))<br>        x = <span class="hljs-variable language_">self</span>.fc3(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><p>这里面的代码几乎完全相同，唯一不同的是最终输出维度是10维，是是因为我们的形状参数就是10维的（后来更新到50维，但是现在开源的还是只有10维），还是那句话，<code>Linear</code>函数里面的<code>W</code>和<code>b</code>都是训练出来的，所以这个模板在姿态和形状上面都可以使用。</p><h2 id="相机回归器">相机回归器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CamRegressor</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, feat_dim=<span class="hljs-number">256</span></span>):<br>        <span class="hljs-built_in">super</span>(CamRegressor, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.fc = nn.Linear(feat_dim, <span class="hljs-number">3</span>)<span class="hljs-comment"># 全连接层：256维→3维</span><br>        nn.init.zeros_(<span class="hljs-variable language_">self</span>.fc.weight)<span class="hljs-comment"># 权重初始化为0</span><br>        nn.init.ones_(<span class="hljs-variable language_">self</span>.fc.bias)<span class="hljs-comment"># 偏置初始化为1</span><br>        nn.init.constant_(<span class="hljs-variable language_">self</span>.fc.bias[<span class="hljs-number">0</span>], <span class="hljs-number">0.9</span>)<span class="hljs-comment"># 第一个偏置设为0.9</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.fc(x)<br></code></pre></td></tr></table></figure><p>这段代码更简单，就是从输入特征中与预测相机参数，还是那话，由于<code>Linear</code>函数的存在，初始值不必太在意，我们这边需要关注一下它的输出的三位向量分别代表什么意思</p><ol type="1"><li>缩放因子（scale）：控制人体在图像中的大小，值越大，人体看起来越大（相机离人体越近）</li><li>水平平移（tx）：控制人体在图像中的水平位置</li><li>垂直平移（ty）：控制人体在图像中的垂直位置</li></ol><p>这些参数可以将 3D 人体模型投影到 2D图像平面上，使其与输入图像中的人体对齐。</p><h2 id="pymaf-x模型核心">PyMAF-X模型（核心）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PyMAF_X</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, pretrained=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>(PyMAF_X, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.backbone = ResNetBackbone(Bottleneck, [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">3</span>])<span class="hljs-comment"># 特征提取骨干网络</span><br>        <span class="hljs-variable language_">self</span>.fpn = FeaturePyramidNetwork([<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">1024</span>, <span class="hljs-number">2048</span>], <span class="hljs-number">256</span>)<span class="hljs-comment"># 特征融合</span><br>        <span class="hljs-variable language_">self</span>.maf_extractor = MAF_Extractor(<span class="hljs-number">2048</span>, <span class="hljs-number">256</span>)<span class="hljs-comment"># 多尺度注意力特征提取</span><br>        <span class="hljs-variable language_">self</span>.pose_regressor = PoseRegressor(<span class="hljs-number">256</span>, <span class="hljs-number">24</span>*<span class="hljs-number">3</span>*<span class="hljs-number">3</span>)<span class="hljs-comment"># 姿态回归</span><br>        <span class="hljs-variable language_">self</span>.shape_regressor = ShapeRegressor(<span class="hljs-number">256</span>, <span class="hljs-number">10</span>)<span class="hljs-comment"># 形状回归</span><br>        <span class="hljs-variable language_">self</span>.cam_regressor = CamRegressor(<span class="hljs-number">256</span>)<span class="hljs-comment"># 相机参数回归</span><br><br>        <span class="hljs-keyword">if</span> pretrained:<br>            <span class="hljs-variable language_">self</span>._load_pretrained_weights()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_load_pretrained_weights</span>(<span class="hljs-params">self</span>):<br>        resnet = resnet50(pretrained=<span class="hljs-literal">True</span>)<br>        backbone_state_dict = <span class="hljs-variable language_">self</span>.backbone.state_dict()<br>        resnet_state_dict = &#123;k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> resnet.state_dict().items() <span class="hljs-keyword">if</span> k <span class="hljs-keyword">in</span> backbone_state_dict&#125;<br>        backbone_state_dict.update(resnet_state_dict)<br>        <span class="hljs-variable language_">self</span>.backbone.load_state_dict(backbone_state_dict)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        features = <span class="hljs-variable language_">self</span>.backbone(x)<span class="hljs-comment"># 提取多尺度特征</span><br>        fpn_features = <span class="hljs-variable language_">self</span>.fpn(features)<span class="hljs-comment"># 融合特征</span><br>        global_feat = <span class="hljs-variable language_">self</span>.maf_extractor(features[-<span class="hljs-number">1</span>])<span class="hljs-comment"># 提取全局特征</span><br>        <br>        pose = <span class="hljs-variable language_">self</span>.pose_regressor(global_feat)<span class="hljs-comment"># 预测姿态</span><br>        shape = <span class="hljs-variable language_">self</span>.shape_regressor(global_feat)<span class="hljs-comment"># 预测形状</span><br>        cam = <span class="hljs-variable language_">self</span>.cam_regressor(global_feat)<span class="hljs-comment"># 预测相机参数</span><br>        <br>        <span class="hljs-keyword">return</span> &#123;<br>            <span class="hljs-string">&#x27;pose&#x27;</span>: pose,<br>            <span class="hljs-string">&#x27;shape&#x27;</span>: shape,<br>            <span class="hljs-string">&#x27;cam&#x27;</span>: cam<br>        &#125;<br></code></pre></td></tr></table></figure><p>铺垫了这么久，终于千呼万唤始出来了，除了其中的预训练权重，其他的基本上是所见即所得了。预训练就是将已经训练好的ResNet50加载下来，将这些知识迁移到PyMAF-X中，站在巨人的肩膀上，大大减少了运算量。</p><p>虽然非常简单，我还是想在这边做一个总结，我们的处理流程</p><blockquote><p>输入图像 → ResNet骨干网络 → 特征金字塔融合 → 全局特征提取 →</p><p>→ 姿态回归器 → 姿态参数</p><p>→ 形状回归器 → 形状参数</p><p>→ 相机回归器 → 相机参数</p></blockquote><h1 id="smpl的实现">SMPL的实现</h1><p>SMPL（Skinned Multi-Person LinearModel）是一种裸体的（skinned），基于顶点（vertex-based）的人体三维模型，能够精确地表示人体的不同形状（shape）和姿态（pose）。</p><h2 id="前置概念">前置概念</h2><p>在进入SMPL模型之前，需要先明确2个概念：</p><p>1.顶点（vertex）：小三角形，看作一个顶点（记为N，在人体中应该是有6890个）</p><p>2.骨骼点：关节点，姿态估计的关键点（记为K，是23个三维旋转向量）</p><h2 id="理论推导">理论推导</h2><p>我们先来一些模型参数<spanclass="math inline"><em>Φ</em> = {<em>T</em>, <em>W</em>, <em>S</em>, <em>J</em>, <em>P</em>}</span>，这些参数不是输入量，这些参数是通过训练得到的，我们的输入参数是<spanclass="math inline">$\vecβ,\vecθ,\vecθ^*$</span></p><p>我们来逐个解释其中的含义：</p><p><spanclass="math inline">$\vecβ=[\vecβ_1,…,\vecβ_{∣β∣}]^T$</span>：形状参数，我们上面已经通过2D单目图像得到了</p><p><spanclass="math inline">$\vecθ=[\vecω^T_0,…,\vecω^T_K]^T$</span>：姿态参数，<spanclass="math inline"><em>w</em><sub><em>k</em></sub></span>指关节k相对于运动树（kinematictree）中的父关节点的旋转轴角度，<spanclass="math inline"><em>ω</em><sub><em>k</em></sub> ∈ <em>R</em><sup>3</sup></span>，我们上面也已经得到了</p><p><spanclass="math inline"><em>W</em> ∈ <em>R</em><sup><em>N</em> × <em>K</em></sup></span>：一组混合权重，BS/QBS混合权重矩阵，即关节点对顶点的影响权重(第几个顶点受哪些关节点的影响且权重分别为多少)</p><p><spanclass="math inline">$S=[S_1,…,S_{|\vecβ|}]∈R^{3N×|\vecβ|}$</span>：由<spanclass="math inline">$\vecβ$</span>带来的顶点位置修正</p><p><spanclass="math inline"><em>P</em> = [<em>P</em><sub>1</sub>, …, <em>P</em><sub><em>k</em></sub>] ∈ <em>R</em><sup>3<em>N</em> × <em>k</em></sup></span>：由<spanclass="math inline"><em>θ⃗</em></span>带来的顶点位置修正</p><p><span class="math inline">$\overlineT∈R^{3N}$</span>：T姿态，作为平均模型，后面的修改都是建立在它的基础上的</p><p>J: 将rest vertices转换成rest joints的矩阵（获取Tpose的关节点坐标的矩阵）[完成顶点到关节的转化]</p><p>对于SMPL模型来说，我们主要分为几个步骤：</p><blockquote><p>1.将shape缩放</p><p>2.根据shape调整joint</p><p>3.调整胖瘦变形</p><p>4.确定姿势</p><p>5.给骨架包裹外衣，蒙皮</p></blockquote><p>SMPL 10个shape的意义分别对应的是：</p><blockquote><p>0代表整个人体的胖瘦和大小，初始为0的情况下，正数变瘦小，负数变大胖（±5）</p><p>1 侧面压缩拉伸，正数压缩</p><p>2 正数变胖大</p><p>3 负数肚子变大很多，人体缩小</p><p>4 代表chest、hip、abdomen的大小，初始为0的情况下，正数变大，负数变小（±5）</p><p>5 负数表示大肚子+整体变瘦</p><p>6 正数表示肚子变得特别大的情况下，其他部位非常瘦小</p><p>7 正数表示身体被纵向挤压</p><p>8 正数表示横向表胖</p><p>9 正数表示肩膀变宽</p></blockquote><p><spanclass="math inline">$M(\vecβ,\vecθ;Φ)=W(T_P(\vecβ,\vecθ),J(\vecβ),\vecθ,W)R^{∣\vecθ∣×∣\vecβ∣}↦R^{3N}$</span>：将形状和位姿参数映射到顶点</p><p><span class="math inline">$W(\overlineT,J,\vecθ,W):R^{3N×3K×|\vecθ|×|W|}↦R^{3N}$</span>:标准线性混合蒙皮.</p><p><spanclass="math inline">$B_P(\vecθ):R^{|θ|}↦R^{3N}$</span>：输入是一系列姿势参数向量，代表姿势的相关形变引发的顶点的修正</p><p><spanclass="math inline"><em>B</em><sub><em>S</em></sub>(<em>β⃗</em>) : <em>R</em><sup>|<em>β</em>|</sup> ↦ <em>R</em><sup>3<em>N</em></sup></span>：输入是一系列姿势参数向量，代表姿势的相关形变引发的顶点的修正</p><p><span class="math inline">$J(\vecβ):R^{∣β∣}↦R^{3K}$</span>:一个预测K个关节位置的函数.</p><p>每个关节<spanclass="math inline"><em>j</em></span>绕轴的旋转角用罗德里格斯公式转换成旋转矩阵：</p><p><span class="math inline">$exp(\vec ω_j)=I+\hat{\overlineω_j}sin(∥\vec ω_j∥)+\hat ω^2_jcos(∥\vecωj∥)$</span></p><p>其中，<spanclass="math inline">$\vecθ=[\vecω^T_0,…,\vecω^T_K]^T$</span>，参数通过<spanclass="math inline">$|\vecθ|=3×23+3=72$</span>定义</p><p><span class="math inline">$\overlineω=\frac{\vecω}{|∣ω|∣}$</span>:为旋转的单位轴，单位化了</p><p><spanclass="math inline">$\hatω$</span>：斜对称矩阵，通过三维向量<spanclass="math inline">$\overline ω$</span>组成</p><p><span class="math inline"><em>I</em>：3 × 3</span>单位矩阵</p><p>下面就是这个函数最为神奇的理论推导的地方（公式太难用latex打出来了，这里我就放一张图片）：</p><p><img src="/picture/SMPL1.jpg" /></p><p>其中，<spanclass="math inline"><em>ω</em><sub><em>k</em>, <em>i</em></sub></span>是混合权重矩阵<spanclass="math inline"><em>W</em></span>的元素，代表第<spanclass="math inline"><em>k</em></span>部分的旋转角度有多少程度影响了第<spanclass="math inline"><em>i</em></span>个顶点。</p><p><span class="math inline">$exp(\vecθ_j)$</span>为局部<spanclass="math inline">3 × 3</span>旋转矩阵，对应结点<spanclass="math inline"><em>j</em></span>。</p><p><span class="math inline">$G_k(\vecθ,J)$</span> 是关节<spanclass="math inline"><em>k</em></span>的世界变换</p><p><spanclass="math inline">$G^′_k(\vecθ,J)$</span>是移除了变换后的相同变换，相当于是在确定你的坐标系</p><p><span class="math inline"><em>J</em></span>:关节回归函数。</p><p>我们假设W是稀疏的，最多允许四个部分影响一个顶点，那这样子我们对我们的公式还可以进行一定的补充：<span class="math display">$$M(\vecβ,\vecθ;Φ)=W(T_P(\vecβ,\vecθ),J(\vecβ),\vecθ,W)\\T_p(\vecβ,\vecθ)=\overline T+B_s(\vecβ)+B_p(\vecθ)$$</span> <spanclass="math inline">$B_S(\vecβ),B_P(\vecθ)$</span>表示由shape和pose引起的相对于SMPL标准模板的顶点向量<spanclass="math inline">$\overline t_i$</span>的偏移量 <spanclass="math display">$$\overline t'_i=\sum_{k=1}^{K}w_{k,i}G^′_k(\vecθ,J(\vec\beta))(\overlinet_i+b_{s,i}(\vec\beta)+b_{P,i}(\vec\theta))$$</span> 其中，<span class="math inline">$b_{S,i}(\vecβ),b_{P,i}(\vecθ)分别B_S(\vecβ),B_P(\vec θ)$</span>的顶点，表示相对于顶点<spanclass="math inline">$\overline t_i$</span>的偏移量。 <spanclass="math display">$$B_S(\vecβ;S)=\sum^\vec{|β|}_{n=1}β_nS_n$$</span></p><p><spanclass="math inline">$\vecβ=[β_1,…,β_{|\vecβ|}]^T，|\vecβ|$</span>是线性形状系数的数量。</p><p><spanclass="math inline"><em>S</em><sub><em>n</em></sub> ∈ <em>R</em><sup>3<em>N</em></sup></span>：形状位移的标准正交主分量</p><p><spanclass="math inline">$S=[S_1,…,S_{|\vecβ|}]∈R^{3N×|\vecβ|}$</span>为形状位移矩阵。线性函数<spanclass="math inline">$B_S(\vecβ;S)$</span>能够完全被矩阵<spanclass="math inline"><em>S</em></span>定义,通过注册训练网络学习。</p><p>定义R：<spanclass="math inline">$R^{|\vecθ|}↦R^{9K}$</span>为把一个位姿向量映射到连接部分相对旋转矩阵的向量上<spanclass="math inline"><em>θ⃗</em></span>,由于我们的骨骼节点有23个关节，则<spanclass="math inline">$R(\vecθ)$</span>是一个<spanclass="math inline">23 × 9 = 207</span>维的向量。它的元素是关节旋转角的sin和cos函数，因此它是一个对于<spanclass="math inline"><em>θ⃗</em></span>的非线性函数。</p><p>但是作者又定义了一个可以让pose blend shape线性的函数：<spanclass="math inline">$R^∗(\vecθ)=(R(\vecθ)−R(\vecθ^∗))$</span>,其中，→θ∗定义了restpose. 定义<span class="math inline">$R_n(\vecθ)$</span>为<spanclass="math inline">$R(\vecθ)$</span>的第n个向量，则与静止模板的偏差为：<span class="math display">$$B_p(\vec \theta;P)=\sum^{9K}_{n=1}(R_n(\vec\theta)-R_n(\vec\theta^*))P_n$$</span> 其中，<spanclass="math inline"><em>P</em><sub><em>n</em></sub> ∈ <em>R</em><sup>3<em>N</em></sup></span>表示顶点偏移的向量。</p><p><spanclass="math inline"><em>P</em> = [<em>P</em><sub>1</sub>, …, <em>P</em><sub>9<em>K</em></sub>] ∈ <em>R</em><sup>3<em>N</em> × 9<em>K</em></sup></span>是所有207个poseblend shape组成的矩阵。<spanclass="math inline">$B_P(\vecθ)$</span>完全被矩阵P定义。</p><p>不同的体型有不同的关节位置，每个关节由其在静止位姿（restpose）中的3D位置表示。关节3D位置相对于身体形状的函数如下： <spanclass="math display">$$J(\vecβ;J,\overline T,S)=J(\overline T+B_S(\vecβ;S))$$</span> 其中，J是将rest vertices转换成restjoints的矩阵，我们从不同的人在不同的姿势的例子中学习回归矩阵J。</p><p>SMPL最后被定义为： <span class="math display">$$M(\vecβ,\vecθ;Φ)=W(T_P(\vecβ,\vecθ;\overline T,S,P),J(\vecβ;J,\overlineT,S),\vecθ,W)$$</span> 每个顶点变为： <span class="math display">$$t_i’=\sum_{k=1}^Kw_{k,i}G'_k(\vec\theta,J(\vec\beta;J,\overlineT,S))t_{P,i}(\vec\beta,\vec\theta;\overline T,S,P)$$</span> 其中 <span class="math display">$$t_{P,i}(\vec\beta,\vec\theta;\overline T,S,P)=\overlinet_i+\sum_{m=1}^{|\vec\beta|}\beta_ms_{m,i}+\sum^{9K}_{n=1}(R_n(\vec\theta)-R_n(\vec\theta^*))p_{n,i}$$</span> 理论推导到这边就基本上完整了</p><h2 id="实现代码">实现代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SMPL</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model_path</span>):<br>        <span class="hljs-comment"># 加载模型参数</span><br>        params = np.load(model_path)<br>        <span class="hljs-variable language_">self</span>.v_template = params[<span class="hljs-string">&#x27;v_template&#x27;</span>]  <span class="hljs-comment"># 模板网格</span><br>        <span class="hljs-variable language_">self</span>.shapedirs = params[<span class="hljs-string">&#x27;shapedirs&#x27;</span>]    <span class="hljs-comment"># 形状主成分</span><br>        <span class="hljs-variable language_">self</span>.posedirs = params[<span class="hljs-string">&#x27;posedirs&#x27;</span>]      <span class="hljs-comment"># 姿态主成分</span><br>        <span class="hljs-variable language_">self</span>.J_regressor = params[<span class="hljs-string">&#x27;J_regressor&#x27;</span>] <span class="hljs-comment"># 关节回归器</span><br>        <span class="hljs-variable language_">self</span>.weights = params[<span class="hljs-string">&#x27;weights&#x27;</span>]        <span class="hljs-comment"># 蒙皮权重</span><br>        <span class="hljs-variable language_">self</span>.kintree_table = params[<span class="hljs-string">&#x27;kintree_table&#x27;</span>] <span class="hljs-comment"># 骨骼树结构</span><br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, beta, theta, get_skin=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-comment"># 计算形状变形</span><br>        v_shaped = <span class="hljs-variable language_">self</span>.v_template + np.dot(<span class="hljs-variable language_">self</span>.shapedirs, beta)<br>        <br>        <span class="hljs-comment"># 计算关节位置</span><br>        J = np.dot(<span class="hljs-variable language_">self</span>.J_regressor, v_shaped)<br>        <br>        <span class="hljs-comment"># 计算姿态旋转矩阵</span><br>        Rs = <span class="hljs-variable language_">self</span>.rodrigues(theta[<span class="hljs-number">3</span>:].reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)))<br>        pose_feature = (Rs - np.eye(<span class="hljs-number">3</span>)).ravel()<br>        <br>        <span class="hljs-comment"># 计算姿态变形</span><br>        v_posed = v_shaped + np.dot(<span class="hljs-variable language_">self</span>.posedirs, pose_feature)<br>        <br>        <span class="hljs-comment"># 构建全局变换矩阵</span><br>        G = <span class="hljs-variable language_">self</span>.with_zeros(np.hstack((Rs, J.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>))))<br>        parent = &#123;i: <span class="hljs-variable language_">self</span>.kintree_table[<span class="hljs-number">0</span>, i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-variable language_">self</span>.kintree_table.shape[<span class="hljs-number">1</span>])&#125;<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, G.shape[<span class="hljs-number">0</span>]):<br>            G[i] = np.dot(G[i], np.linalg.inv(G[parent[i]]))<br>        <br>        <span class="hljs-comment"># 蒙皮过程</span><br>        T = np.tensordot(<span class="hljs-variable language_">self</span>.weights, G, axes=[[<span class="hljs-number">1</span>], [<span class="hljs-number">0</span>]])<br>        rest_shape_h = np.hstack((v_posed, np.ones((v_posed.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>))))<br>        v = np.<span class="hljs-built_in">sum</span>(T * rest_shape_h.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span>), axis=<span class="hljs-number">2</span>)[:, :<span class="hljs-number">3</span>]<br>        <br>        <span class="hljs-keyword">return</span> (v, J) <span class="hljs-keyword">if</span> get_skin <span class="hljs-keyword">else</span> J<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">rodrigues</span>(<span class="hljs-params">self, r</span>):<br>        <span class="hljs-comment"># 罗德里格斯公式：将旋转向量转换为旋转矩阵</span><br>        theta = np.linalg.norm(r, axis=<span class="hljs-number">1</span>).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        r = r / (theta + <span class="hljs-number">1e-8</span>)<br>        r = r.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>        cost = np.cos(theta)<br>        sint = np.sin(theta)<br>        rx = np.array([[<span class="hljs-number">0</span>, -r[:, <span class="hljs-number">2</span>], r[:, <span class="hljs-number">1</span>]],<br>                       [r[:, <span class="hljs-number">2</span>], <span class="hljs-number">0</span>, -r[:, <span class="hljs-number">0</span>]],<br>                       [-r[:, <span class="hljs-number">1</span>], r[:, <span class="hljs-number">0</span>], <span class="hljs-number">0</span>]]).transpose(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>        R = np.eye(<span class="hljs-number">3</span>) + sint * rx + (<span class="hljs-number">1</span> - cost) * np.matmul(rx, rx)<br>        <span class="hljs-keyword">return</span> R<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">with_zeros</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 在变换矩阵底部添加一行 [0, 0, 0, 1]</span><br>        <span class="hljs-keyword">return</span> np.vstack((x, np.array([[<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>]])))<br></code></pre></td></tr></table></figure><p>有了上面的推导，代码基本上就是所见即所得，上面也有一些注释，很好理解</p>]]></content>
    
    
    <categories>
      
      <category>SMPL系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>SMPL</tag>
      
      <tag>PxMAF-X</tag>
      
      <tag>3D人体模型恢复</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性表整理</title>
    <link href="/2025/07/04/%E7%BA%BF%E6%80%A7%E8%A1%A8%E6%95%B4%E7%90%86/"/>
    <url>/2025/07/04/%E7%BA%BF%E6%80%A7%E8%A1%A8%E6%95%B4%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="线性表">线性表</h1><h2 id="线性表的基础">线性表的基础</h2><p>线性表的之间定义我就不再多说了，直接来看一下它的基本运算：</p><p>（1）创建一个空的线性表（create）（2）删除数据表中的所有线性结构（clear） （3）求线性表的长度（length）（4）在第<code>i</code>个位置插图一个元素（insert）（5）删除第<code>i</code>个位置的元素（remove）（6）搜索元素，检查某个元素<code>x</code>在线性表中是否出现，并返回<code>x</code>的位置（search）（7）返回线性表中第<code>i</code>个数据元素的值（visit）（8）按序访问线性表的每一个数据元素（traverse）</p><p>我们可以直接产生面向对象的程序设计</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<span class="hljs-comment">//这里面我使用了一个模板，但是实际上不一定需要，只是为了更具有普适性</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">linearlist</span>&#123;<br>    <span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">create</span><span class="hljs-params">()</span> </span>= <span class="hljs-number">0</span>;<br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">int</span> <span class="hljs-title">length</span><span class="hljs-params">()</span> <span class="hljs-type">const</span> </span>= <span class="hljs-number">0</span>;<span class="hljs-comment">//在类的成员函数里面能加const的都加上const</span><br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">insert</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span> </span>= <span class="hljs-number">0</span>;<br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">remove</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span> </span>= <span class="hljs-number">0</span>;<br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">int</span> <span class="hljs-title">search</span><span class="hljs-params">(<span class="hljs-type">const</span> T &amp;x)</span> <span class="hljs-type">const</span> </span>= <span class="hljs-number">0</span>;<span class="hljs-comment">//遇到负责类型作为参数的时候，就直接const + 复杂类型 + &amp;这样最节省时间和空间</span><br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> T <span class="hljs-title">visit</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span>b <span class="hljs-type">const</span> </span>= <span class="hljs-number">0</span>;<br>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-type">void</span> <span class="hljs-title">traverse</span><span class="hljs-params">()</span> <span class="hljs-type">const</span> </span>= <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">virtual</span> ~<span class="hljs-built_in">list</span>()&#123;&#125;;<span class="hljs-comment">//为什么这个地方不再构建纯虚函数，我在后面应该会单开一篇来讲纯虚函数的事</span><br>&#125;;<br></code></pre></td></tr></table></figure><p>在上面的代码里除了析构函数以外，其他基本上都是纯虚函数，这样相当于勒令衍生类解决这些问题，这样一个基本的线性表的就构建好了，我们为什么在上面只是设置成员函数，但是没有去设置数据成员？因为线性表有多种表示方式，既可以是顺序表，也可以是链表，链表又可以分为单双链表，顺序表也有多种表达方式，不同的表示方式我们要设置的私有数据成员也不同，我们只能够放到衍生类里面去实现。</p><h2 id="顺序表类">顺序表类</h2><h3 id="顺序列表基础申明">顺序列表基础申明</h3><p>顺序实现是我们存放数据最自然的一种方式，基本上所有事务我要把它归类，首先都是这么干的，它的基础逻辑就是数组，不过在C++中，数组确实不太好用（主要是在申明的时候就要给定最大容量，这对于经常要使用变量的我们来说还是十分复杂的），但是通过指针，我们就可以很清爽地规避掉这个问题：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">seqlist</span>: <span class="hljs-keyword">public</span> linearlist&lt;T&gt;&#123; <span class="hljs-comment">//通过public的方式来继承linearlist</span><br>    <span class="hljs-keyword">private</span>:<br>T *data;<br>    <span class="hljs-type">int</span> curlength;<span class="hljs-comment">//当下长度</span><br>    <span class="hljs-type">int</span> maxsize;<span class="hljs-comment">//最大长度</span><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">doublespace</span><span class="hljs-params">()</span></span>;<span class="hljs-comment">//私有的成员函数，将空间双倍，为什么将他设置为私有？因为这个基本上只有在成员函数里面才会运用到，不需要对用户开放，当然，如果你要坚持写在public里面，也没有问题</span><br>    <span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">seqlist</span>(<span class="hljs-type">int</span> startsize);<span class="hljs-comment">//构造函数</span><br>    ~<span class="hljs-built_in">seqlist</span>();<span class="hljs-comment">//析构函数，来清除动态数组的</span><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">clear</span><span class="hljs-params">()</span></span>;<span class="hljs-comment">//来清除其他东西的</span><br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">length</span><span class="hljs-params">()</span> <span class="hljs-type">const</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">insert</span><span class="hljs-params">(<span class="hljs-type">int</span> i, <span class="hljs-type">const</span> T &amp;x)</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">remove</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">search</span><span class="hljs-params">(<span class="hljs-type">const</span> T &amp;x)</span> <span class="hljs-type">const</span></span>;<br>    <span class="hljs-function">T <span class="hljs-title">visit</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span> <span class="hljs-type">const</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">traverse</span><span class="hljs-params">()</span> <span class="hljs-type">const</span></span>;<br>&#125;;<br></code></pre></td></tr></table></figure><p>基本上还是跟上面一样的说明，但是这次就不能再打太极了，必须解决，不过一个习惯就是不要放在类里面解决（除非真的很短）</p><h3id="析构函数clearlengthvisittraverse函数的实现">析构函数，clear，length，visit，traverse函数的实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//~seqlist的实现</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br>seqlist&lt;T&gt;::~<span class="hljs-built_in">seqlist</span>()&#123;<br>    <span class="hljs-keyword">delete</span> [] data;<br>&#125;<br><span class="hljs-comment">//clear的实现</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">void</span> seqlist&lt;T&gt;::<span class="hljs-built_in">clear</span>()&#123;<br>    curlength = <span class="hljs-number">0</span>;<br>    maxsize = <span class="hljs-number">0</span>;<br>&#125;<br><span class="hljs-comment">//length的实现</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">int</span> seqlist&lt;T&gt;::<span class="hljs-built_in">length</span>()<span class="hljs-type">const</span>&#123;<br>    <span class="hljs-keyword">return</span> curlength;<br>&#125;<br><span class="hljs-comment">//visit的实现</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br>T seqlist&lt;T&gt;::<span class="hljs-built_in">visit</span>(<span class="hljs-type">int</span> i)<span class="hljs-type">const</span>&#123;<br>    <span class="hljs-keyword">return</span> data[i];<br>&#125;<br><span class="hljs-comment">//traverse的实现</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">void</span> seqlist&lt;T&gt;::<span class="hljs-built_in">traverse</span>()<span class="hljs-type">const</span>&#123;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt;= curlength; i++)<br>        cout &lt;&lt; data[i] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>   cout &lt;&lt; endl;<br>&#125;<br></code></pre></td></tr></table></figure><p>上面是最简单的几个功能的实现，基本上所有学习过C++的读者都可以轻松自己编写，除了<code>traverse</code>函数的时间复杂度是<spanclass="math inline"><em>O</em>(<em>n</em>)</span>，其他的时间复杂度都是<spanclass="math inline"><em>O</em>(1)</span>，接下来几个比较能够体现顺序类列表的特点，我分开来列：</p><h3 id="构造函数的实现">构造函数的实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//构造函数的实现</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br>seqlist&lt;T&gt;::<span class="hljs-built_in">seqlist</span>(<span class="hljs-type">int</span> startsize)&#123;<br>    data = <span class="hljs-keyword">new</span> T [startsize];<br>    maxsize = startsize;<br>    currentlength = <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>这个其实也非常简单（或许我应该把它列在上面的，算了，<del>懒得动</del>）</p><h3 id="search的实现">search的实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">//search的实现</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">int</span> seqlist&lt;T&gt;::<span class="hljs-built_in">search</span>(<span class="hljs-type">const</span> T &amp;x)<span class="hljs-type">const</span>&#123;<br>    <span class="hljs-type">int</span> i;<br>    <span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i &lt; curlength &amp;&amp; data[i] != x; i++);<br>    <span class="hljs-keyword">return</span> ((i == curlength)?<span class="hljs-number">-1</span>:i);<br>&#125;<br></code></pre></td></tr></table></figure><p>其实讲真的，基本上所有人都能看得出来这块挺麻烦的，但是搜索就是这样，除非储存下标，不然就是需要遍历，时间复杂度就是<spanclass="math inline"><em>O</em>(<em>n</em>)</span>级别的。</p><h3id="doublespace和search函数的实现">doublespace和search函数的实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//doublespace和search函数的实现</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">void</span> seqlist&lt;T&gt;::<span class="hljs-built_in">doublespace</span>()&#123;<br>    T *tmp = data;<br>    maxsize *= <span class="hljs-number">2</span>;<br>    data = <span class="hljs-keyword">new</span> T [maxsize];<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; curlength; i++)<br>        data[i] = tmp[i];<br>    <span class="hljs-keyword">delete</span> [] tmp;<br>&#125;<br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">void</span> seqlist&lt;T&gt;::<span class="hljs-built_in">insert</span>(<span class="hljs-type">int</span> i,<span class="hljs-type">const</span> T &amp;x)&#123;<br><span class="hljs-keyword">if</span>(curlength == maxsize)<br><span class="hljs-built_in">doublespace</span>();<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = i; j &lt; curlength; j++)<br>        data[j + <span class="hljs-number">1</span>] = data[j];<br>    data[i] = x;<br>    curlength++;<br>&#125;<br></code></pre></td></tr></table></figure><p>基本上十分明显了，很简单就是我要插入在第<code>i</code>的位置，那么我把自从第<code>i</code>往后的每一位都向后挪一个位置，再把第<code>i</code>位变成我要的<code>x</code>这样子就完成了，这里就是顺序表和链表最大的不同，不过两者基本上都是<spanclass="math inline"><em>O</em>(<em>n</em>)</span>的时间复杂度，因为顺序表知道下标但是挪动需要花一定的时间，而链表是挪动不用花时间但是不知道下表（但是实际上可以解决）</p><h3 id="remove函数的实现">remove函数的实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">//remove的实现</span><br><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">void</span> seqlist&lt;T&gt;::<span class="hljs-built_in">remove</span>(<span class="hljs-type">int</span> i)&#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = i; j &lt; curlength; j++)<br>        data[j] = data[j + <span class="hljs-number">1</span>];<br>    curlength--;<br>&#125;<br></code></pre></td></tr></table></figure><p>顺序表就这么多内容了，基本上没有什么例外，确实比较简单，链表在<code>move</code>函数那边比较具有迷惑性，需要好好解释一下的我们接下来探讨</p><h2 id="单链表">单链表</h2><h3 id="单链表类的定义">单链表类的定义</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">slinklist</span>: <span class="hljs-keyword">public</span> linearlist&lt;T&gt;&#123;<br>    <span class="hljs-keyword">private</span>:<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">node</span>&#123;<br>            T data;<br>            node *next;<span class="hljs-comment">//这两个是链表的基本元素</span><br>            <span class="hljs-built_in">node</span>(<span class="hljs-type">const</span> T &amp;x, node *n = <span class="hljs-literal">NULL</span>)&#123;data = x; next = n;&#125;<span class="hljs-comment">//这里面是node的构造函数</span><br>            <span class="hljs-built_in">node</span>():<span class="hljs-built_in">next</span>(<span class="hljs-literal">NULL</span>)&#123;&#125;<span class="hljs-comment">//这个是没有初始化的时候的构造函数，将next指针指向NULL是避免错误的一个非常好的做法</span><br>            ~<span class="hljs-built_in">node</span>()&#123;&#125;<br>        &#125;;<br>    node *head;<span class="hljs-comment">//这个是头节点</span><br>    <span class="hljs-type">int</span> curlength;<span class="hljs-comment">//这个是当下的长度</span><br>    <span class="hljs-function">node *<span class="hljs-title">move</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span> <span class="hljs-type">const</span></span>;<br>    <span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">slinklist</span>();<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">clear</span><span class="hljs-params">()</span></span>;<br>    ~<span class="hljs-built_in">slinklist</span>()&#123;<span class="hljs-built_in">clear</span>();<span class="hljs-keyword">delete</span> head;&#125;<span class="hljs-comment">//clear就是将所有除头节点以外的节点全部清除</span><br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">length</span><span class="hljs-params">()</span> <span class="hljs-type">const</span> </span>&#123;<span class="hljs-keyword">return</span> curlength&#125;;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">insert</span><span class="hljs-params">(<span class="hljs-type">int</span> i,<span class="hljs-type">const</span> T &amp;x)</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">remove</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">search</span><span class="hljs-params">(<span class="hljs-type">const</span> T &amp;x)</span></span><br><span class="hljs-function">             T <span class="hljs-title">visit</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span> <span class="hljs-type">const</span></span>;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">traverse</span><span class="hljs-params">()</span> <span class="hljs-type">const</span></span>;<br>&#125;;<br></code></pre></td></tr></table></figure><p>这里里面的定义基本上都跟上面一样，不过这里需要注意的就是<code>node</code>作为结构体，也具有构造函数和析构函数，形式跟类差不多</p><h3 id="move函数的实现">move函数的实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">//move函数的实现</span><br><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-keyword">typename</span> slinklist&lt;T&gt;::node *slinklist&lt;T&gt;::<span class="hljs-built_in">move</span>(<span class="hljs-type">int</span> i) <span class="hljs-type">const</span>&#123;<span class="hljs-comment">//这个地方需要申明的就是typename是一个可有可无的量，其本质就是对编译器申明这里是一个变量名，可能有些不太先进的编译器没有办法识别出来</span><br>    node *p = head;<br>    <span class="hljs-keyword">while</span>(i-- &gt;= <span class="hljs-number">0</span>)p = p -&gt; next;<span class="hljs-comment">//这里面i-- &gt;= 0总共会循环i + 1次</span><br>    <span class="hljs-keyword">return</span> p;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里面为什么是<code>i + 1</code>次循环？而不是<code>i</code>我们的头节点并不是我们的第0个节点，我们要从头节点移动到第0个节点需要移动1次，第一个节点需要2次……以此类推，你要到第<code>i</code>个节点，就需要<code>i + 1</code>次，那既然如此，我们为什么不直接去除掉<code>head</code>节点，来考虑剩下来的问题？这个问题我们下文会考虑</p><h3 id="构造函数的实现-1">构造函数的实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">//slinklist的实现</span><br><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br>slinklist&lt;T&gt;::<span class="hljs-built_in">slinklist</span>()&#123;<br>head = <span class="hljs-keyword">new</span> node;<br>    curlength = <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>非常简单，没有什么好讲的（<del>所以你干嘛写它呢？</del>）</p><h3 id="clear函数的实现">clear函数的实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">//clear函数的实现</span><br><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">void</span> slinklist &lt;T&gt; ::<span class="hljs-built_in">clear</span>()&#123;<br>node *p = head-&gt;next ,*q;<br>    head-&gt;next = <span class="hljs-literal">NULL</span>;<br>    <span class="hljs-keyword">while</span>(p != <span class="hljs-literal">NULL</span>)&#123;<br>q = p-&gt;next;<br>        <span class="hljs-keyword">delete</span> p;<br>        p = q;<span class="hljs-comment">//删除，然后移动到下一个节点</span><br>    &#125;<br>    curlength = <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>也是非常的简单，不多说了</p><h3 id="insert和remove函数的实现">insert和remove函数的实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">//insert函数的实现</span><br><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">void</span> slinklist&lt;T&gt;::<span class="hljs-built_in">insert</span>(<span class="hljs-type">int</span> i, <span class="hljs-type">const</span> T &amp;x)&#123;<br>node *pos;<br>    pos = <span class="hljs-built_in">move</span>(i - <span class="hljs-number">1</span>);<br>    pos-&gt;next = <span class="hljs-keyword">new</span> <span class="hljs-built_in">node</span>(x, pos-&gt;next);<span class="hljs-comment">//这里使用了我在定义里面写的node的构造函数</span><br>    curlength++;<br>&#125;<br><span class="hljs-comment">//remove函数的实现</span><br><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">void</span> slinklist&lt;T&gt;::<span class="hljs-built_in">remove</span>(<span class="hljs-type">int</span> i)&#123;<br>node *pos, *delp;<br>    pos = <span class="hljs-built_in">move</span>(i - <span class="hljs-number">1</span>);<br>    delp = pos-&gt;next;<br>    pos-&gt;next = delp-&gt;next;<br>    <span class="hljs-keyword">delete</span> delp;<br>    curlength--;<br>&#125;<br></code></pre></td></tr></table></figure><p>终于来了点有意思的东西了，第一个问题：为什么<code>move</code>函数的参数是<code>i - 1</code>?而不是<code>i</code>呢？我们要去除第<code>i</code>个节点，自然就是要将<code>i - 1</code>和<code>i + 1</code>链接起来，所以实际上，我们将<code>pos</code>移到<code>i - 1</code>的位置是便于操作的，因为我们这边是单链表，你找你的下家容易，但是你去找上家比较的困难</p><p>另外再说，为什么我们需要将<code>node</code>后面写上<code>x, pos-&gt;next</code>的参数，可以参考我在定义里面写的<code>node(const T &amp;x, node *n = NULL)&#123;data = x; next = n;&#125;</code>我们将这里面的<code>x</code>变为一个新的节点的<code>data</code>然后将原来<code>pos-&gt;next</code>变作这个新节点的<code>next</code>，最后将<code>post-&gt;next</code>改为这个新节点的地址，如果我们不要求代码的美观度这么高，我们可以写得明显一些：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs C++">node *tmp = <span class="hljs-keyword">new</span> node;<br>tmp-&gt;data = x;<br>tmp-&gt;next = pos-&gt;next;<br>pos-&gt;next = tmp;<br></code></pre></td></tr></table></figure><p>上面这四行代码可以达到同样的效果</p><p>在<code>remove</code>函数的实现中，注意<code>delp</code>函数的使用，因为<code>delp</code>函数其实是记下来给用来释放空间的，不然会产生内存泄漏。</p><h3id="searchvisittraverse函数的实现">search，visit，traverse函数的实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//search函数的实现</span><br><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">int</span> slinklist&lt;T&gt;::<span class="hljs-built_in">search</span>(<span class="hljs-type">const</span> T &amp;x)<span class="hljs-type">const</span>&#123;<br>node *p = head-&gt;next;<br>    <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">while</span>(p != <span class="hljs-literal">NULL</span> &amp;&amp; p-&gt;data != x)&#123;<br>p = p-&gt;next;<br>        i++;<br>    &#125;<br>    <span class="hljs-keyword">if</span>(p == <span class="hljs-literal">NULL</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<span class="hljs-comment">//如果p是到NULL的时候停下来的说明没有找到x，x不存在在顺序链表里</span><br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-keyword">return</span> i;<br>&#125;<br><span class="hljs-comment">//visit函数的实现</span><br><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br>T slinklist&lt;T&gt;::<span class="hljs-built_in">visit</span>(<span class="hljs-type">int</span> i)<span class="hljs-type">const</span>&#123;<br><span class="hljs-keyword">return</span> <span class="hljs-built_in">move</span>(i)-&gt;data;<br>&#125;<br><span class="hljs-comment">//traverse函数的实现</span><br><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">void</span> slinklist&lt;T&gt;::<span class="hljs-built_in">traverse</span>()<span class="hljs-type">const</span>&#123;<br>node *p = head-&gt;next;<br>    <span class="hljs-keyword">while</span>(p != <span class="hljs-literal">NULL</span>)&#123;<br>        cout &lt;&lt; p-&gt;data &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>p = p-&gt;next;<br>    &#125;<br>    cout &lt;&lt; endl;<br>&#125;<br></code></pre></td></tr></table></figure><p>这三个函数还是十分简单的，基本上就是遍历了，没有什么太过困难的。</p><h3 id="无头结点的函数实现">无头结点的函数实现</h3><p>但是</p><p>你觉得，这就结束了吗？</p><p><strong>不！</strong></p><p>我们还要尝试无头结点的情况下面的单链表，判断为什么拥有头节点是一件更好的事情，我们来尝试一下无头结点情况下的<code>insert</code>和<code>remove</code>函数</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">//无头结点下的insert函数的实现</span><br><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">void</span> slinklist&lt;T&gt;::<span class="hljs-built_in">insert</span>(<span class="hljs-type">int</span> i, <span class="hljs-type">const</span> T &amp;x)&#123;<br><span class="hljs-keyword">if</span>(i == <span class="hljs-number">0</span>)&#123;<br>p = head;<br>        head = <span class="hljs-keyword">new</span> <span class="hljs-built_in">node</span>(x,p);<br>    &#125;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(i &gt; <span class="hljs-number">0</span>)&#123;<br>        p = <span class="hljs-built_in">move</span>(i - <span class="hljs-number">2</span>);<br>        p-&gt;next = <span class="hljs-keyword">new</span> <span class="hljs-built_in">node</span>(x,p-&gt;next);<span class="hljs-comment">//其实在i &gt; 0的情况下其实差不多，没有什么太大的区别，就是只能移动i - 2位了</span><br>    &#125;<br>    curlength++;<br>&#125;<br><span class="hljs-comment">//无头结点下的remove函数的实现</span><br><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-title class_">T</span>&gt;<br><span class="hljs-type">void</span> slinklist&lt;T&gt;::<span class="hljs-built_in">remove</span>(<span class="hljs-type">int</span> i)&#123;<br>node *pos, *delp;<br>    <span class="hljs-keyword">if</span>(i == <span class="hljs-number">0</span>)&#123;<br>        delp = head;<br>        head = delp-&gt;next;<br>    &#125;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(i &gt; <span class="hljs-number">0</span>)&#123;<br>p = <span class="hljs-built_in">move</span>(i - <span class="hljs-number">2</span>);<br>        delp = p-&gt;next;<br>        p-&gt;next = delp-&gt;next;<br>    &#125;<br>    <span class="hljs-keyword">delete</span> delp;<br>    curlength--;<br>&#125;<br></code></pre></td></tr></table></figure><p>明显可以看出来复杂得多了，因为我们需要对于有<code>i == 0</code>的情况进行专门的判断，我建议有精力的读者可以自己用笔来画画图，来理解一下为什么这里面<code>i == 0</code>需要专门判断，笔者本来也想写一写然后贴图片上去的，但是作业还没有写完（悲），就不能继续写了</p><h2 id="总结">总结</h2>]]></content>
    
    
    <categories>
      
      <category>数据结构知识整理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>链表</tag>
      
      <tag>数组</tag>
      
      <tag>更新中</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一道分块处理的题目</title>
    <link href="/2025/07/03/%E5%88%86%E5%9D%97%E5%A4%84%E7%90%86%E7%9A%84%E4%B8%80%E9%81%93%E9%A2%98/"/>
    <url>/2025/07/03/%E5%88%86%E5%9D%97%E5%A4%84%E7%90%86%E7%9A%84%E4%B8%80%E9%81%93%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<p>我们来看一下这个题目：</p><p>JokerXue想要租房子，而他的心上人对数字十分敏感。他发现，对于一间租金为<em>p</em>元/月的房子，他的心上人的心理不悦度是这样计算的：</p><ol type="1"><li>首先将 <em>p</em> 看做一个由数字组成的字符串（不带前导 0）；</li><li>然后，如果 <em>p</em> 的最后一个字符是0，就去掉它。重复这一过程，直到 <em>p</em> 的最后一个字符不是 0；</li><li>记 <em>p</em> 的长度为 a<em>，如果此时 p</em> 的最后一位是5，则不悦度为 2<em>a</em>−1；否则为 2<em>a</em>。</li></ol><p>例如，850 代表的不悦度为 3，而 880 则为 4，9999 为 8。</p><p>JokerXue想要在<em>T</em>个不同的地区租房子，在每个地区他都有一个租金的心理预期[L, R]，现在他想要知道在这些地区能够使得心上人<strong>心理不悦度最低并且租金较低</strong>的方案。</p><p>JokerXue要去准备他的“万兽之王”演唱会，所以请聪明的你帮忙进行最优解的计算。</p><h3 id="输入格式">输入格式</h3><p>输入文件的第一行包含一个正整数 <em>T</em>，表示JokerXue想要租房子的地区的数量。</p><p>接下来的T<em>行，每行包含两个空格分隔的正整数L</em>,<em>R</em>，表示他的租金心理预期。</p><h3 id="输出格式">输出格式</h3><p>对于每个地区，在单独的一行内输出能使心上人的心理不悦度最低的租金值。如果结果不唯一，则输出<strong>最小</strong>的那个。</p><h3 id="样例">样例</h3><p>输入</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-number">3</span><br><span class="hljs-symbol">998 </span><span class="hljs-number">1002</span><br><span class="hljs-symbol">998 </span><span class="hljs-number">2002</span><br><span class="hljs-symbol">4000 </span><span class="hljs-number">6000</span><br></code></pre></td></tr></table></figure><p>输出</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-number">1000</span><br><span class="hljs-number">1000</span><br><span class="hljs-number">5000</span><br></code></pre></td></tr></table></figure><h3 id="数据范围">数据范围</h3><ul><li>对于 20%的数据，<em>L</em>,<em>R</em>≤2000；</li><li>对于 100% 的数据，<em>T</em>≤100，1 ≤<em>L</em>≤ <em>R</em> ≤1e9。</li></ul><p>这是我们学校ACMOJ上面的一道题，以下是题目链接：</p><p><a href="https://acm.sjtu.edu.cn/OnlineJudge/problem/2618">租购 ·ACMOJ</a></p><p>我们来分析以下这个题目，我们根据数据规模可以很轻松地判断出这里不能够直接遍历，因为时间不够，那么从常用的角度来说，就是剩下了两种时间复杂度<spanclass="math inline">$O(\log n)和O(\sqrtn)$</span>（常数级的时间复杂度我们就不考虑了，其实笔者的一个朋友有相关的想法，但是没有最后实践成功，后续笔者可能会继续想一想这个问题），在这里面我们不难发现，对数级的时间复杂度固然更为简便，但是似乎没有合适的算法来实现，我们自然而然就会往根号级的算法去想，而最为直接的根号级算法，就是分块处理：</p><p>我们来思考一下，其实我们先明确一点，我们将<em>p</em>所有计入不悦度运算的位数称为<strong>有效位</strong>，那么我们可以很明显地看出，有效位是越少越好的，而且有效位少的优先级应该比末尾是5的有限级更高，因为末尾是5，结果只是在原有基础上-1，而如果有效位能够少一个，那么不悦度的结果可以-2</p><p>那我们达成共识，现在可行的范围内找有效位尽可能少的，然后在有效位已经最少的情况下，看看有效位的末尾能不能取到5。</p><p>这是我们处理的原则，那么接下来如何分块呢？</p><p>我们先想一下<code>r - l</code>的范围，如果<code>r - l</code>小于<em>1e5</em>，那么我们其实可以直接范围内的数进行遍历，计算出每一个数的不悦度，这样就比较，取最小，最后计算机的计算次数差不过是在<em>1e6</em>这个级别的，不会有超时的情况。</p><p>那如果<code>r - l</code>大于<em>1e5</em>呢？那是不是<strong>在区间之间，至少存在一个后五位都是0的数</strong>，那我们实际上，后5位存在非零数位的数，必然不会符合我们的最优要求，所以我们只要将<code>r</code>和<code>l</code>都除以<em>1e5</em>，然后再在新得到的区间里面遍历就可以了，这个算法的复杂度计算次数大概是<em>1e9/1e5=1e4</em>这个级别的，算上我们的操作数，至多也就在<em>1e5</em>级别，比我们上一种情况的遍历还要更快速一些。</p><p>OK，理论可行，接下来就是具体实现了，细节方面还有很多要考虑的，之前笔者在交这道题的时候好多次都WA了，就是因为有些细节没有考虑清楚。</p><p>我们先来设计一个直接计算不悦度的函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">byd</span><span class="hljs-params">(<span class="hljs-type">long</span> <span class="hljs-type">long</span> x)</span></span>&#123;<br><span class="hljs-type">int</span> cnt = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">while</span>(x%<span class="hljs-number">10</span> == <span class="hljs-number">0</span>)<br>x /= <span class="hljs-number">10</span>;<br><span class="hljs-type">bool</span> flag = <span class="hljs-literal">false</span>;<br><span class="hljs-keyword">if</span>(x%<span class="hljs-number">10</span> == <span class="hljs-number">5</span>)<br>flag = <span class="hljs-literal">true</span>;<br><span class="hljs-keyword">while</span>(x &gt; <span class="hljs-number">0</span>)&#123;<br>x /= <span class="hljs-number">10</span>;<br>cnt++;<br>&#125;<br>cnt = cnt * <span class="hljs-number">2</span> - flag;<span class="hljs-comment">//flag为true，那么相当于多尾数是5，在原有基础上-1</span><br><span class="hljs-keyword">return</span> cnt;<br>&#125;<br></code></pre></td></tr></table></figure><p>函数名我的设计理念就是“不悦度”汉语拼音的缩写（bu）（yue）（du），请不要产生无端联想~</p><p>我们再来设计一个<code>solve()</code>函数，直接解决从<code>l</code>到<code>r</code>的范围问题：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">long</span> <span class="hljs-type">long</span> <span class="hljs-title">solve</span><span class="hljs-params">(<span class="hljs-type">long</span> <span class="hljs-type">long</span> l,<span class="hljs-type">long</span> <span class="hljs-type">long</span> r)</span></span>&#123;<br><span class="hljs-type">long</span> <span class="hljs-type">long</span> ans1 = l;<br><span class="hljs-type">int</span> ans2 = <span class="hljs-built_in">byd</span>(l);<br><span class="hljs-keyword">for</span>(<span class="hljs-type">long</span> <span class="hljs-type">long</span> i = l;i &lt;= r; i++)&#123;<br><span class="hljs-type">int</span> tmp = <span class="hljs-built_in">byd</span>(i);<br><span class="hljs-keyword">if</span>(tmp &lt; ans2)&#123;<br>ans1 = i;<br>ans2 = tmp;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> ans1;<br>&#125;<br></code></pre></td></tr></table></figure><p>基本上就是最简单的判断，没有什么好说的</p><p>我们再来写一下<code>main()</code>函数，记住其中有很多非常容易错的细节：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-type">const</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> N = <span class="hljs-number">1e5</span>;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> n;<br>cin &gt;&gt; n;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; n; i++)&#123;<br><span class="hljs-type">long</span> <span class="hljs-type">long</span> l, r;<br>cin &gt;&gt; l &gt;&gt; r;<br><span class="hljs-type">long</span> <span class="hljs-type">long</span> x = r - l;<br><span class="hljs-keyword">if</span>(x &lt;= N)<br>cout &lt;&lt; <span class="hljs-built_in">solve</span>(l,r) &lt;&lt; endl;<span class="hljs-comment">//如果小于1e5，那么直接丢给solve()</span><br><span class="hljs-keyword">else</span>&#123;<br><span class="hljs-keyword">if</span>(l &lt; N)&#123;<span class="hljs-comment">//这里就是第一种特殊情况，如果l比1e5小，那么l就不能直接处理，需要进行判断</span><br><span class="hljs-keyword">if</span>(r &gt;= <span class="hljs-number">5</span> * N)<span class="hljs-comment">//因为你的x是大于1e5的，所以r至少是一个五位数，五位数中不悦度最低的就是5*1e5，但我们不能确保r的范围能够到达那个程度，我们还要基于此做一次判断</span><br>cout &lt;&lt; <span class="hljs-built_in">solve</span>(l, <span class="hljs-number">5</span> * N) &lt;&lt; endl;<br><span class="hljs-keyword">else</span><br>cout &lt;&lt; <span class="hljs-built_in">solve</span>(l, r) &lt;&lt; endl;<br>&#125;<br><span class="hljs-keyword">else</span>&#123;<br><span class="hljs-keyword">if</span>(l % N == <span class="hljs-number">0</span>)<span class="hljs-comment">//这里需要记住，在/1e5之后，我们的l应该是向上取整的，r是向下取整的，所以l还要对于边界判断</span><br>l /= N;<br><span class="hljs-keyword">else</span>&#123;<br>l /= N;<br>l++;<br>&#125;<br>r /= N;<span class="hljs-comment">//r是向下取整，符合C++中的除号运算符</span><br>cout &lt;&lt; <span class="hljs-built_in">solve</span>(l,r) * N &lt;&lt; endl;<br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们将三段代码合并到一块，就可以得到AC的结果（笔者实测过）：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-type">const</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> N = <span class="hljs-number">1e5</span>;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">byd</span><span class="hljs-params">(<span class="hljs-type">long</span> <span class="hljs-type">long</span> x)</span></span>&#123;<br><span class="hljs-type">int</span> cnt = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">while</span>(x%<span class="hljs-number">10</span> == <span class="hljs-number">0</span>)<br>x /= <span class="hljs-number">10</span>;<br><span class="hljs-type">bool</span> flag = <span class="hljs-literal">false</span>;<br><span class="hljs-keyword">if</span>(x%<span class="hljs-number">10</span> == <span class="hljs-number">5</span>)<br>flag = <span class="hljs-literal">true</span>;<br><span class="hljs-keyword">while</span>(x &gt; <span class="hljs-number">0</span>)&#123;<br>x /= <span class="hljs-number">10</span>;<br>cnt++;<br>&#125;<br>cnt = cnt * <span class="hljs-number">2</span> - flag;<span class="hljs-comment">//flag为true，那么相当于多尾数是5，在原有基础上-1</span><br><span class="hljs-keyword">return</span> cnt;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">long</span> <span class="hljs-type">long</span> <span class="hljs-title">solve</span><span class="hljs-params">(<span class="hljs-type">long</span> <span class="hljs-type">long</span> l,<span class="hljs-type">long</span> <span class="hljs-type">long</span> r)</span></span>&#123;<br><span class="hljs-type">long</span> <span class="hljs-type">long</span> ans1 = l;<br><span class="hljs-type">int</span> ans2 = <span class="hljs-built_in">byd</span>(l);<br><span class="hljs-keyword">for</span>(<span class="hljs-type">long</span> <span class="hljs-type">long</span> i = l;i &lt;= r; i++)&#123;<br><span class="hljs-type">int</span> tmp = <span class="hljs-built_in">byd</span>(i);<br><span class="hljs-keyword">if</span>(tmp &lt; ans2)&#123;<br>ans1 = i;<br>ans2 = tmp;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> ans1;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> n;<br>cin &gt;&gt; n;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; n; i++)&#123;<br><span class="hljs-type">long</span> <span class="hljs-type">long</span> l, r;<br>cin &gt;&gt; l &gt;&gt; r;<br><span class="hljs-type">long</span> <span class="hljs-type">long</span> x = r - l;<br><span class="hljs-keyword">if</span>(x &lt;= N)<br>cout &lt;&lt; <span class="hljs-built_in">solve</span>(l,r) &lt;&lt; endl;<span class="hljs-comment">//如果小于1e5，那么直接丢给solve()</span><br><span class="hljs-keyword">else</span>&#123;<br><span class="hljs-keyword">if</span>(l &lt; N)&#123;<span class="hljs-comment">//这里就是第一种特殊情况，如果l比1e5小，那么l就不能直接处理，需要进行判断</span><br><span class="hljs-keyword">if</span>(r &gt;= <span class="hljs-number">5</span> * N)<span class="hljs-comment">//因为你的x是大于1e5的，所以r至少是一个五位数，五位数中不悦度最低的就是5*1e5，但我们不能确保r的范围能够到达那个程度，我们还要基于此做一次判断</span><br>cout &lt;&lt; <span class="hljs-built_in">solve</span>(l, <span class="hljs-number">5</span> * N) &lt;&lt; endl;<br><span class="hljs-keyword">else</span><br>cout &lt;&lt; <span class="hljs-built_in">solve</span>(l, r) &lt;&lt; endl;<br>&#125;<br><span class="hljs-keyword">else</span>&#123;<br><span class="hljs-keyword">if</span>(l % N == <span class="hljs-number">0</span>)<span class="hljs-comment">//这里需要记住，在/1e5之后，我们的l应该是向上取整的，r是向下取整的，所以l还要对于边界判断</span><br>l /= N;<br><span class="hljs-keyword">else</span>&#123;<br>l /= N;<br>l++;<br>&#125;<br>r /= N;<span class="hljs-comment">//r是向下取整，符合C++中的除号运算符</span><br>cout &lt;&lt; <span class="hljs-built_in">solve</span>(l,r) * N &lt;&lt; endl;<br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>后来笔者与舍友讨论，应该还会存在常数级算法的可能，但是笔者没有能够实现，如果有读者愿意和笔者交流常数级算法的可能性，笔者将不胜感激。</p><p>感谢 <span class="citation"data-cites="Geniustanker">@Geniustanker</span>与笔者的讨论，这个题目也是他提供给笔者的。</p>]]></content>
    
    
    <categories>
      
      <category>算法题(C++)</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分块算法</tag>
      
      <tag>时间复杂度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>斐波那契数列的矩阵快速幂算法</title>
    <link href="/2025/07/03/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E9%A2%9D%E6%95%B0%E5%88%97%E7%9A%84%E7%9F%A9%E9%98%B5%E5%BF%AB%E9%80%9F%E5%B9%82%E7%AE%97%E6%B3%95/"/>
    <url>/2025/07/03/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E9%A2%9D%E6%95%B0%E5%88%97%E7%9A%84%E7%9F%A9%E9%98%B5%E5%BF%AB%E9%80%9F%E5%B9%82%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>我们在学习C++算法的时候会遇到一个十分基本的问题：</p><blockquote><p>我们都知道斐波那契数列：1，1，2，3，5，8，13，<spanclass="math inline">⋯</span>，现在已知第一个1记为第一项，第二个1记为第二项，2记为第三项，以此类推，现在我向里面输入一个<spanclass="math inline"><em>n</em></span>，请你告诉我数列中第<spanclass="math inline"><em>n</em></span>项的数值是多少？</p></blockquote><p>这个题很多人第一眼会感觉十分简单，确实，它确实不难，我们都十分熟悉斐波那契数列的递推公式：<spanclass="math inline"><em>a</em><sub><em>n</em></sub> = <em>a</em><sub><em>n</em> − 1</sub> + <em>a</em><sub><em>n</em> − 2</sub></span><spanclass="math inline">(<em>n</em> ≥ 2)</span></p><p>这天然就给了我们递归的土壤：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">Fibonacci</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span></span>&#123;<br>    <span class="hljs-keyword">if</span>(n == <span class="hljs-number">1</span> || n == <span class="hljs-number">2</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">else</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">Fibonacci</span> (n - <span class="hljs-number">1</span>) + <span class="hljs-built_in">Fibonacci</span> (n - <span class="hljs-number">2</span>);<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> n;<br>    cin &gt;&gt; n;<br>    cout &lt;&lt; <span class="hljs-built_in">Fibonacci</span>(n) &lt;&lt;endl;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>基本上系统学习过C++的同学都可以写出这段代码，但是这里存在一个非常明显的不足：时间复杂度太高，粗略估计：<spanclass="math inline"><em>O</em>(2<sup><em>n</em></sup>)</span>，在这个条件下，基本上<spanclass="math inline"><em>n</em> ≥ 50</span>的时候计算机就要算很久才能出结果的（我之前记得计算机每秒的运算次数大概在<spanclass="math inline">10<sup>9</sup></span>次左右，所以原本以为在40的时候差不多就要卡住了，但是实际操作下来的话50左右才会被卡住，只能说是计算能力又进步了，我out了​​）</p><p>当然，进一步想，我们的斐波那契数列计算太过于重复了，每一次递归，都要再计算一遍很多之前已经计算出结果的函数，那如果我们用一个数组，将我们计算过的数和相数都放在里面，不就大大简便了呢？所以这就是动态规划：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> n;<br>cin &gt;&gt; n;<br><span class="hljs-type">long</span> <span class="hljs-type">long</span> *dp = <span class="hljs-keyword">new</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> [n + <span class="hljs-number">1</span>];<br>dp[<span class="hljs-number">1</span>] = <span class="hljs-number">1</span>;<br>dp[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">2</span>; i &lt;= n; i++)<br>dp[i] = dp[i - <span class="hljs-number">1</span>] + dp[i - <span class="hljs-number">2</span>];<br>cout &lt;&lt; dp[n] &lt;&lt;endl;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>（我的码风不是特别规范，大家见谅，这里面的算是最基础的动态规划，比较简单，我就不详细说明了）</p><p>通过这个算法，我们已经将时间复杂度降到了<spanclass="math inline"><em>O</em>(<em>n</em>)</span>的级别，基本上在longlong数值范围内的斐波那契数列值我们都可以计算出来了（超出longlong数值范围的部分属于数字处理了，在这篇博客里面暂时不讨论，<del>当然不是笔者不会的原因</del>）</p><p>不过正经讲，在笔者做过的信息学竞赛题目中，这类结果一般是让你取模的，所以说更高效的算法也是有必要的。</p><p>在算法结构中，有一种十分巧妙的方法叫做快速幂。如果我们要计算<spanclass="math inline"><em>x</em><sup><em>n</em></sup></span>，这里面最为直接的方法就是将<spanclass="math inline"><em>n</em></span>个<spanclass="math inline"><em>x</em></span>相乘，时间复杂度为<spanclass="math inline"><em>O</em>(<em>n</em>)</span>，但这个方法可以进一步简化，将时间复杂度降到<spanclass="math inline"><em>O</em>(log<sub>2</sub><em>n</em>)</span>，代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> x, n;<br>cin &gt;&gt; x &gt;&gt; n;<br><span class="hljs-type">int</span> res = <span class="hljs-number">1</span>;<br><span class="hljs-keyword">while</span>(n &gt; <span class="hljs-number">0</span>)&#123;<br><span class="hljs-keyword">if</span>(n &amp; <span class="hljs-number">1</span>)res *= x;<br>x = x * x;<br>n &gt;&gt; = <span class="hljs-number">1</span>;<br>&#125;<br>cout &lt;&lt; res &lt;&lt; endl;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>这种方法其实非常好理解，就是将<spanclass="math inline"><em>n</em></span>转换为二进制，每一次只取<spanclass="math inline"><em>n</em></span>的末位来看，如果是<spanclass="math inline">1</span>，那么就将结果乘上<spanclass="math inline"><em>x</em></span>，如果是<spanclass="math inline">0</span>，那就不用管，同时，由于数位不断地左移（注意，<spanclass="math inline"><em>n</em> &gt;  &gt;  = 1</span>是将<spanclass="math inline"><em>n</em></span>右移，但是从位数上来说，就是左移），<spanclass="math inline"><em>x</em></span>需要自增，也就是变为<spanclass="math inline"><em>x</em><sup>2</sup></span>。</p><p>这个算法的时间复杂度，就是只有<spanclass="math inline"><em>O</em>(log<sub>2</sub><em>n</em>)</span>。</p><p>我们知道了这个方法，对于我们解决这个问题有什么帮助呢？</p><p>对于斐波那契数列，特殊矩阵的幂可以计算出斐波那契额数列的结果：</p><p><span class="math display">$$\begin{align*} \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 0 \end{bmatrix}\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 0 \end{bmatrix} &amp;=\begin{bmatrix} 2 &amp; 1 \\ 1 &amp; 0 \end{bmatrix} \\ \begin{bmatrix}2 &amp; 1 \\ 1 &amp; 0 \end{bmatrix} \begin{bmatrix} 1 &amp; 1 \\ 1&amp; 0 \end{bmatrix} &amp;= \begin{bmatrix} 3 &amp; 2 \\ 2 &amp; 1\end{bmatrix} \\ \begin{bmatrix} 3 &amp; 2 \\ 2 &amp; 1 \end{bmatrix}\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 0 \end{bmatrix} &amp;=\begin{bmatrix} 5 &amp; 3 \\ 3 &amp; 2 \end{bmatrix}\end{align*}$$</span></p><p><span class="math display">$$\begin{matrix}\vdots \\\end{matrix}$$</span></p><p><span class="math display">$$\begin{align*}\begin{bmatrix} a_n &amp; a_{n-1} \\ a_{n-1} &amp; a_{n-2}\end{bmatrix} \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 0 \end{bmatrix}&amp;= \begin{bmatrix} a_n + a_{n-1} &amp; a_n \\ a_{n-1} + a_{n-2}&amp; a_{n-1} \end{bmatrix} = \begin{bmatrix} a_{n+1} &amp; a_n \\ a_n&amp; a_{n-1} \end{bmatrix} \end{align*}$$</span></p><p>从中我们可以很轻易地得到： <span class="math display">$$\left[\begin{matrix}1&amp;1\\1&amp;0\end{matrix}\right]^n=\left[\begin{matrix}a_{n+1}&amp;a_n\\a_n&amp;a_{n-1}\end{matrix}\\\right]$$</span></p><p>其中<spanclass="math inline"><em>a</em><sub><em>n</em></sub></span>是斐波那契数列中的第<spanclass="math inline"><em>n</em></span>项</p><p>其实通过这些铺垫，我们通过矩阵快速幂来解决斐波那契问题的答案已经呼之欲出了，最后的一道拦路虎就是如何运用C++来计算矩阵的乘法，这个问题我觉得没有单独拎出来讨论的必要（<del>绝对不是因为笔者懒了不想写了</del>,现在已经凌晨1：30了，好困）</p><p>接下来是完整的代码（幸好之前已经写过了，<del>可以早点睡觉</del>）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-keyword">typedef</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> ll;<br><span class="hljs-keyword">typedef</span> vector&lt;ll&gt; vec;<br><span class="hljs-keyword">typedef</span> vector&lt;vec&gt; mac;<span class="hljs-comment">//mac就是用来表示矩阵的</span><br><span class="hljs-comment">//计算矩阵的相乘</span><br><span class="hljs-function">mac <span class="hljs-title">calmartix</span><span class="hljs-params">(mac a,mac b)</span></span>&#123;<br><span class="hljs-function">mac <span class="hljs-title">ans</span><span class="hljs-params">(<span class="hljs-number">2</span>, vec(<span class="hljs-number">2</span>) )</span></span>;<span class="hljs-comment">//只需要一个2*2的矩阵就可以了</span><br><span class="hljs-type">int</span> cnt;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; <span class="hljs-number">2</span>; i++)<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">2</span>; j++)&#123;<br>cnt = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k = <span class="hljs-number">0</span>;k &lt; <span class="hljs-number">2</span>;k++)<br>cnt += a[i][k] * b[k][j];<span class="hljs-comment">//矩阵的计算</span><br>ans[i][j] = cnt;<br>&#125;<br><span class="hljs-keyword">return</span> ans;<br>&#125;<br><span class="hljs-comment">//快速幂</span><br><span class="hljs-function">mac <span class="hljs-title">quickcal</span><span class="hljs-params">(mac a,ll n)</span></span>&#123;<br><span class="hljs-function">mac <span class="hljs-title">res</span><span class="hljs-params">(<span class="hljs-number">2</span>, vec(<span class="hljs-number">2</span>))</span></span>;<br>res[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>] = <span class="hljs-number">1</span>;<br>res[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;<br>res[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;<br>res[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>] = <span class="hljs-number">0</span>;<span class="hljs-comment">//这时候的res是一个单位矩阵</span><br><span class="hljs-keyword">while</span>(n &gt; <span class="hljs-number">0</span>)&#123;<br><span class="hljs-keyword">if</span>(n &amp; <span class="hljs-number">1</span>) res = <span class="hljs-built_in">calmartix</span>(res , a);<br>a = <span class="hljs-built_in">calmartix</span>(a , a);<br>n &gt;&gt;= <span class="hljs-number">1</span>;<br>&#125;<span class="hljs-comment">//矩阵的快速幂</span><br><span class="hljs-keyword">return</span> res;<br>&#125; <br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> n;<br>cin &gt;&gt; n;<br><span class="hljs-function">mac <span class="hljs-title">ans</span><span class="hljs-params">(<span class="hljs-number">2</span>,vec(<span class="hljs-number">2</span>))</span></span>;<br><span class="hljs-function">mac <span class="hljs-title">a</span><span class="hljs-params">(<span class="hljs-number">2</span>,vec(<span class="hljs-number">2</span>))</span></span>;<br>a[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;<br>a[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>] = <span class="hljs-number">1</span>;<br>a[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;<br>a[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>] = <span class="hljs-number">0</span>;<span class="hljs-comment">//这里的a就是我们之前讨论的特殊矩阵</span><br>ans = <span class="hljs-built_in">quickcal</span>(a ,n);<br>cout &lt;&lt; ans[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>] &lt;&lt; endl; <span class="hljs-comment">//这里你也可以cout &lt;&lt; ans[1][0] &lt;&lt; endl;都一样看你心情</span><br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>矩阵的计算次数是一个常数，我们在考虑时间复杂度的时候可以忽略，这个算法的时间复杂度就是<spanclass="math inline"><em>O</em>(<em>l</em><em>o</em><em>g</em><sub>2</sub><em>n</em>)</span></p><p>有兴趣的读者可以自己动手亲自写一写~</p>]]></content>
    
    
    <categories>
      
      <category>算法题(C++)</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>快速幂</tag>
      
      <tag>矩阵</tag>
      
      <tag>最优时间复杂度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>最大连续子序列求和</title>
    <link href="/2025/07/02/%E6%9C%80%E5%A4%A7%E8%BF%9E%E7%BB%AD%E5%AD%90%E5%BA%8F%E5%88%97%E6%B1%82%E5%92%8C/"/>
    <url>/2025/07/02/%E6%9C%80%E5%A4%A7%E8%BF%9E%E7%BB%AD%E5%AD%90%E5%BA%8F%E5%88%97%E6%B1%82%E5%92%8C/</url>
    
    <content type="html"><![CDATA[<h2 id="最大连续子序列求和">最大连续子序列求和</h2><p>题目：</p><blockquote><p>给你一个整数列，<spanclass="math inline"><em>A</em><sub>1</sub>, <em>A</em><sub>2</sub>, <em>A</em><sub>3</sub>, ⋯, <em>A</em><sub><em>n</em></sub></span>，在其中找到一个连续的子链<spanclass="math inline"><em>A</em><sub><em>i</em></sub>, <em>A</em><sub><em>i</em> + 1</sub>, ⋯, <em>A</em><sub><em>j</em></sub>(1 ≤ <em>i</em> ≤ <em>j</em> ≤ <em>N</em>)</span>使得<spanclass="math inline">$\sum_{k=i}^{j}A_k$</span>的值最大，如果所有的数都是负数，则规定最大连续子链和为<spanclass="math inline">0</span></p></blockquote><p>这个其实是非常简单的一道题，随着思维的深入，时间复杂度可以多次降低，比如说，我们肯定可以想到一个时间复杂度为<spanclass="math inline"><em>O</em>(<em>N</em><sup>3</sup>)</span>的算法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxSubsequenceSum</span><span class="hljs-params">(<span class="hljs-type">int</span> A[],<span class="hljs-type">int</span> size,<span class="hljs-type">int</span> &amp;start,<span class="hljs-type">int</span> &amp;end)</span></span>&#123;<br>    <span class="hljs-type">int</span> result = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; size; i++)<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = i;j &lt; size; j++)&#123;<br>            <span class="hljs-type">int</span> count = <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k = i;k &lt;= j; k++)<br>                count += A[k];<br>            <span class="hljs-keyword">if</span>(count &gt; result)&#123;<br>                result = count;<br>                start = i;<br>                end = j;<br>            &#125;<br>&#125;<br>    <span class="hljs-keyword">return</span> result;<br>&#125;<br></code></pre></td></tr></table></figure><p>这个想法比较简单，我就不写注释了。简单分析一下，这里面其实有一个十分浪费的地方，就是每次都需要重新计算<spanclass="math inline">$\sum_{k=i}^{j}A_k$</span>的值，这种做法实际上是没什么必要的，我们完全可以进行预处理，这样时间复杂度降到了<spanclass="math inline"><em>O</em>(<em>N</em><sup>2</sup>)</span>，这就是前缀和的方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxSubsequenceSum</span><span class="hljs-params">(<span class="hljs-type">int</span> A[],<span class="hljs-type">int</span> size,<span class="hljs-type">int</span> &amp;start,<span class="hljs-type">int</span> &amp;end)</span></span>&#123;<br>    <span class="hljs-type">int</span> result = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">if</span>(size == <span class="hljs-number">1</span>)&#123;<br>        start = <span class="hljs-number">0</span>;<br>        end = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(result, A[<span class="hljs-number">0</span>]);<span class="hljs-comment">//如果只有一个数，那么就不用想那么多，这个数是正数，就是这个正数，这个数是负数，就是0</span><br>    &#125;<br>    <span class="hljs-type">int</span> *sum = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span> [size<span class="hljs-number">+1</span>];<br>    sum[<span class="hljs-number">0</span>] = A[<span class="hljs-number">0</span>];<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>;i &lt; size; i++)<br>        sum[i] = sum[i<span class="hljs-number">-1</span>] + A[i];<span class="hljs-comment">//前缀和，即sum[i]就是A[0]+A[1]+...+A[i]的值</span><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; size; i++)<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = i;j &lt; size; j++)&#123;<br>            <span class="hljs-keyword">if</span>(result &lt;= (sum[j] - sum[i]))&#123;<br>                start = i;<br>                end = j;<br>                result = (sum[j] - sum[i]);<span class="hljs-comment">//这样，我们只需要用sum[j] - sum[i]就可以表示从i到j中所有元素的和</span><br>            &#125; <br>&#125;<br>    <span class="hljs-keyword">return</span> result;<br>&#125;<br></code></pre></td></tr></table></figure><p>笔者这边申明一下，如果返回结果是<spanclass="math inline">0</span>，那就不需要再打出来<code>start</code>和<code>end</code>的值了。具体实现可以写在主函数里，笔者这里就不再赘述了。还有就是<code>sum[j]-sum[i]</code>到底需不需要加括号，这个关于C++运算符号优先级的问题，笔者打算后面专门开一篇来介绍。</p><p>可能有人会对我说：</p><p>主播主播，你的方法确实很强，但是还是太吃时间复杂度了，有没有更简便的方法推荐呢？</p><p>有的兄弟有的</p><p>（理解一下笔者的精神状态）</p><p>好了，正经点，其实还有一种<spanclass="math inline"><em>O</em>(<em>n</em>)</span>的方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxSubsequenceSum</span><span class="hljs-params">(<span class="hljs-type">int</span> A[],<span class="hljs-type">int</span> size,<span class="hljs-type">int</span> &amp;start,<span class="hljs-type">int</span> &amp;end)</span></span>&#123;<br>    <span class="hljs-type">int</span> i = <span class="hljs-number">0</span>, result = <span class="hljs-number">0</span>, count = <span class="hljs-number">0</span>;<br>    start = <span class="hljs-number">0</span>;<span class="hljs-comment">//把起点都初始化一下</span><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; size; j++)&#123;<span class="hljs-comment">//j往后移，计算这时候的子链和</span><br>        count += A[j];<br>        <span class="hljs-keyword">if</span>(count &gt; result)&#123;<span class="hljs-comment">//如果当下子链和比我之前的结果大，那么就将结果替换为当下的子链和</span><br>            result = count;<br>            start = i;<br>            end = j;<br>&#125;<br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(count &lt; <span class="hljs-number">0</span>)&#123;<span class="hljs-comment">//重点：如果我当下的子链和是小于零的，那么这一段我直接抛掉，将我计算的起始点放到j+1的位置</span><br>            count = <span class="hljs-number">0</span>;<br>            i = j + <span class="hljs-number">1</span>;<br>&#125;<br>&#125;<br>    <span class="hljs-keyword">return</span> result;<br>&#125;<br></code></pre></td></tr></table></figure><p>对于这个方法，我写了一些备注，不过可能还是有读者没有看懂，我仔细来说一下：<code>i</code>是起点，是我当下计算子列的起始点，然后我去用<code>j</code>来遍历<code>A[]</code>这个数组，将<code>j</code>的结果累计到<code>count</code>中，每一次循环中，对<code>count</code>进行一次检查，如果<code>count</code>小于<code>0</code>，那么直接将<code>i</code>设为<code>j+1</code>，而<code>count</code>归零。</p><p>为什么这样做是正确的？因为任何一个子数列加上一个和小于0的子数列都会使合成的总数列和变小，那么既然如此，我就不计入和小于0的子数列，这一段，在我眼中，属于“亏本”的状态，不管它前置还是后置，我们都不会加上它，简单来说，就是<strong>如果一段连续数列的和是负数，它就不会是最大子序列的开头。</strong></p><p>如果从数学上理解了这点，这道题就迎刃而解了。</p>]]></content>
    
    
    <categories>
      
      <category>算法题(C++)</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>最优时间复杂度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>写在最前面</title>
    <link href="/2025/07/02/%E5%86%99%E5%9C%A8%E6%9C%80%E5%89%8D%E9%9D%A2/"/>
    <url>/2025/07/02/%E5%86%99%E5%9C%A8%E6%9C%80%E5%89%8D%E9%9D%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="欢迎你来到牧丛的博客">欢迎你来到牧丛的博客！</h1><p>在正式浏览这个博客的主要内容之前，我希望你能够抽出几分钟的时间来阅读一下这篇文章，或许能够节约你的一部分时间。</p><p>其实笔者在2025年2月份期间，就开始着手搭建自己的博客，当时使用的是matery主题，当时也更新了一些文章，但是一直存在一些格式上不适配的现象，后来在朋友的推荐下选择了fluid的主题。但是交大大一下的课程堪称恐怖，笔者拼劲全力，实在没有办法在保证课内学习质量的情况下持续更新博客，无奈只能停更。现在已是暑假，笔者决定重整旗鼓，重新开始博客的更新。下面是我2025年年初写的前言（略有修改）：</p><p>首先，我想先简单介绍一下有关我博客名字的一些事情。在网址和Github那里，你可以看到我注册的名称是“MYCDherder”，而进入博客后的自我介绍中，会告诉你我的昵称叫“牧丛”，这是我个人习惯所导致的。我是个不怎么会起名字的人，我几乎所有的账户，倘若可以用中文表示，那就一律起名为“牧丛”，而若是需要英文，我一般就会使用“MYCD”。但是由于“MYCD”的名字过短，不能通过Github的名称审核，我只好将两个名字融合起来，“牧丛”没有直接对应的英文单词，我就取了其中的“牧”字，将其翻译为“herder”，“放牧的人”，两者一结合，问题就迎刃而解了。</p><p>再说说笔者，笔者目前是一名上海交通大学的本科生，就读于信息工程专业。在初高中的学习生活中，笔者一直算不上一个出色的学生，也常常被周围巨佬们的天才表现所震撼。在大学的生活中，笔者也往往比较迟钝，很多消息往往知道得比别人慢，产生了一定的信息差。像个人博客这种东西，也是几个月前，笔者发现一个高中同学已经创建了属于自己的博客时才了解到的。</p><p>当然，笔者创立这个博客，并不是为了盲目地跟风。笔者初入大学，对于大学的学习生活，依然没有能够找到一条稳定而高效的路径。显而易见，初高中以熟练度为主的应试方法必然不会符合大学的教育模式，单纯的高分也不是中国本科教育的目的。笔者建立这个博客，其实也是对自己本科学习方法的一种探索。当然，不同于毫无意义的胡乱尝试，创建并运营博客有着一些明显的好处：</p><p>第一，博客的运营需要持续的更新，持续的更新就需要持续的学习与思考，对于自己博客的运营其实也是一种自我的督促。</p><p>第二，更新博客的过程其实也是“费曼学习法”，博客更新的内容是公开的，实质上就是将笔者所学的知识用自己的语言，以通俗易懂的方式教授给别人。在这个过程中，笔者对于知识的理解也会更加透彻。</p><p>当然，创立的博客的好处当然不止这些，但限于篇幅原因，笔者不再继续探讨。其实，笔者更多是想把这个博客做成一个类似于学习笔记的东西，当然，这并不意味着笔者会呆板地去照抄教材。笔者希望的，是能够在这些基础学科中找到一些大家忽略的细节，进行一些深度的思考。</p><p>除了单纯的巩固细节之外，笔者还希望能够对于一些现有的模型进行自己的思考和阐释。当然，这些思考不一定是笔者率先提出来的，笔者所表述出来的语言也不一定精准，肯定会出现许多的瑕疵，但是笔者认为这个过程对于一个求学者来说是必要的。</p><p>在这个过程中，笔者可能会有一些想到一半就无法继续下去的想法，到时候可能会单独开一个列表，欢迎大家和笔者一起思考和讨论。</p><p>最后，笔者第一次创建并且尝试运营博客，可能会出现很多的错误和疏漏，如果读者愿意反馈给我，笔者将不胜感激。</p><p>最后的最后，非常感谢大家能够读完这篇文章，愿我们一起学习，一起进步！</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
